[["index.html", "Learn R 1 Introduction", " Learn R By KazeeRa AliaR 1 Introduction This book is a beginner resource for R programming. Each chapter is a tutorial. I highly recommend gaining a firm foundation in programming basics and data types (chapters 3 and 4) as a prerequisite for downstream analysis in R. Test out this app made using R. Move the slider! Each chapter contains: description of concept examples of concept link to quiz practice problem and solution What is programming/coding? It is the process of creating a set of instructions that tell a computer how to perform a task. It can be done using a variety of computer languages, such as R, Java, and python. Advantages of R? Here are some benefits of R programming for both beginners and experts. R is open-source, free and accessible (no license/subscription required!). In addition, the R community is very active, helpful and build extensive libraries that may suit your needs. Supports cross-platform usage (ie. machine-independent), which means it can be used on Windows, Mac OS, etc. the same way. It is an interpreted language, meaning you can see the output of your code line-by-line. In other words, it doesnt need a compiler to make executable programs. R is also an object-oriented programming language. Why should you learn R? R has a comprehensive development environment, which will help you perform statistical computing as well as software development. Delve into statistical computing and analysis. Analyze large data sets for data science via parallel/distributed computing. Great for data cleansing and wrangling. Produce powerful graphics, that is, high quality visualizations, even interactive graphs! Compatible with other languages such as C, C++, FORTRAN as well as Java, Python. Use to interact with databases such as MySQL. Perform machine learning. Create web applications without any web development knowledge using RShiny. Other resources to learn R: Course-like: link Comprehensive tutorial pages: link Refresher slides: link Source code The tutorials (chapters as R markdown files) and source files for this book can be downloaded here: https://github.com/kazeera/learn-r. This book was created using bookdown. "],["installation.html", "2 Installation 2.1 Install R 2.2 Install RStudio 2.3 Terms", " 2 Installation This chapter provides installation instructions for R and RStudio (developing environment, user interface) on your local system. 2.1 Install R Follow link on website for your operating system link Select CRAN Comprehensive R Archive Network (CRAN) is a collection of sites which carry identical material, consisting of the R distribution(s), the contributed extensions, documentation for R, and binaries. 2.2 Install RStudio Download community/open-source version for free on website link RStudio is an integrated development environment (IDE) for R that provides an alternative interface to R RStudio provides integrated support for editing and executing R code and documents. Divided into 4 panes Read more about RStudio link Write code interactively in console pane and make scripts in program pane Practice: the Workspace link 2.3 Terms Path = the route to a file (file = file or folder) Absolute path = the route starts at home node e.g. /home/Documents/myReport (mac) or C:(windows), C:.txt Relative path = refers to file that you can access if you start at current working directory e.g starting in the home folder: Documents/myReport Read more: What Is a Path? link Directory = folder Working directory = which folder are you/R currently working in? When you import or export files using a relative path, it will be relative to this working directory. Script = a list of commands that are executed by a certain program, saved as files with extension .R. Save code in the scripting area and run chunks or all code. Command = instruction given by a user telling a computer to do something. Commands are given to R / implemented using functions (code to execute instructions). Examples of commands: getwd() # print your current working directory setwd(a_path) # sets your working directory q() # quit Type commands in RStudio in the program pane (also called console) starting at the &gt;. # Get working directory getwd() ## [1] &quot;C:/Users/Khokha lab/Documents/GitHub/learn-r&quot; # Paths path = &quot;Documents&quot; #relative path path = &quot;C:/Users/YourName/Documents&quot; #absolute path # # Set working directory # setwd(path) # equivalent to setwd( &quot;C:/Users/YourName/Documents&quot;) "],["r-programming-basics.html", "3 R Programming Basics 3.1 Variable Declaration 3.2 Basic Data Types 3.3 Operators 3.4 Practice", " 3 R Programming Basics Objective: Explore the syntax and basic features of R. We will cover: packages and functions variable declaration basic data types (numeric, logical, character) operators (arithmetic, logical, relational) A large part was based on this tutorial: http://www.sthda.com/english/wiki/easy-r-programming-basics#basic-arithmetic-operations Features of R R is an interpreted language, which means it runs code line by line and can be used interactively. Other R users make code in the form of packages, which contain functions and data sets for you to use in your code. Sources of packages: base (already included in R), CRAN (install using install.packages()), BioConductor ( link for bioinformatics). We use RStudio to work interactively and make scripts, but we can use any code editor and the default R console. # use a base R function to print &quot;Hello world&quot; on the console print(&quot;Hello world&quot;) ## [1] &quot;Hello world&quot; Note: Hello, world is often the first program/command written by people learning to code (see link). A quick note on functions: - Functions are a group of statements that together perform a specific task - Functions have a name, e.g. setwd, getwd - We can call functions (also called commands in this context) in R for convenience (so we dont have to rewrite the code) Functions have the format: function_name(arguments) Arguments are required or optional parameters used by the function to accomplish the action Functions can return a value (or not) Use ? or help() command To find information for a particular function # ?print # help(print) # Type a comma and press tab to see arguments (function parameters) in RStudio print(x = &quot;Hello world&quot;) print(x = 33.9431249, digits = 4) 3.1 Variable Declaration Assignment operator, represented as &lt;-, assigns values on the right to objects on the left. Variables are a named place to store data that reserves a spot your memory. You need to declare variables before using them. Rules for naming variables in R - can consist of letters, numbers and the dot or underline characters (e.g. rna2, rna_2, .rna_1) - case sensitive (e.g. rna_counts != RNA_counts) - cannot start with a number or . followed by a number (e.g. .2rna is invalid) - should not be a reserved word (type ?reserved to see list in R) In the example below, x is called a variable or an object in R. Once youve assigned a value to a variable, it appears in your environment (i.e. workspace). # Run the line of code below so the value of x is 3 x &lt;- 3 # The function ls() returns the list of objects in your current environment ls() # To remove a variable, use the function rm() rm(x) # equivalent 3.2 Basic Data Types numeric - integer (e.g. 1L, 2L) and double (has decimal - e.g. 1.1, 422.33) character (e.g. hi, 2) - Note: a string = more than 1 characters logical (TRUE or FALSE) Variables have a data type depending on what value you give to it. # Numeric object: How old are you? my_age &lt;- 28 # Character object: What&#39;s your name? my_name &lt;- &quot;Sanjay&quot; # logical object: Are you a scientist? # (yes/no) &lt;=&gt; (TRUE/FALSE) is_scientist &lt;- TRUE Its possible to use the function class() to see what type a variable is: class(my_age) ## [1] &quot;numeric&quot; class(my_name) ## [1] &quot;character&quot; typeof(my_age) ## [1] &quot;double&quot; You can also use the functions is.numeric(), is.character(), is.logical() to check whether a variable is numeric, character or logical, respectively. For instance: is.numeric(my_age) ## [1] TRUE is.numeric(my_name) ## [1] FALSE If you want to change the type of a variable to another one, use the as.* functions, including: as.numeric(), as.character(), as.logical(), etc. class(my_age) ## [1] &quot;numeric&quot; my_age &lt;- as.character(my_age) class(my_age) ## [1] &quot;character&quot; 3.3 Operators Arithmetic operators (urany and binary) * + and - (unary operators) * + (addition) * - (subtraction) * \\* (multiplication) * / (division) * ^ (exponentiation) # Unary minus num &lt;- 12 # Addition 3 + num ## [1] 15 # Substraction 7 - num ## [1] -5 # Multiplication 3 * 7 ## [1] 21 # Divison num/3 ## [1] 4 # Exponentiation 3^5 ## [1] 243 # Modulos: returns the remainder of the division of 8/3 10 %% 3 ## [1] 1 # Basic arithmetic functions log2(num) # logarithms base 2 of x ## [1] 3.584963 log10(num) # logaritms base 10 of x ## [1] 1.079181 exp(num) # Exponential of x ## [1] 162754.8 b &lt;- 2 log(x = num, base = b) # custom base ## [1] 3.584963 # trig functions sin(b); cos(b); tan(b) #; is used to seperate code on the same line ## [1] 0.9092974 ## [1] -0.4161468 ## [1] -2.18504 # Store expression in variable result &lt;- 3 + 7 log2(result) ## [1] 3.321928 Tip: combine variables and your text using sprintf() or paste()/paste0(). paste() concatenates a bunch of characters/strings together. sprintf() employs C-style string formatting commands by including format specifiers (which start with the % character) within the string. # Declare your variables my_name &lt;- &quot;Kazeera&quot; my_age &lt;- round(23.7, digits = 0) # Example: Say &quot;My name is ___ and my age is ___&quot; paste(&quot;My name is &quot;, my_name, &quot; and I am &quot;, my_age, &quot; years old.&quot;, sep=&quot;&quot;) ## [1] &quot;My name is Kazeera and I am 24 years old.&quot; sprintf(&quot;My name is %s and I am %s years old.&quot;, my_name, my_age) # use %f for numbers and %s for strings ## [1] &quot;My name is Kazeera and I am 24 years old.&quot; Logical operators - return TRUE or FALSE, important for later on when we learn about control structures Relational operators used to compare between values &lt; for less than \\&gt; for greater than &lt;= for less than or equal to \\&gt;= for greater than or equal to == for equal to each other != not equal to each other # Guess the value of each operation x &lt;- 3 5 &lt; x ## [1] FALSE x &lt; 2 ## [1] FALSE x &lt;- 2 x &lt;= 2 ## [1] TRUE x != 3 ## [1] TRUE Boolean operators used as conjunctions to perform Boolean operations ! Logical NOT # convert &amp; Element-wise logical AND # will be false if at least one element is false Element-wise logical OR # will be true if at least one element is true # Assign logical values to variables im_tall &lt;- TRUE im_short &lt;- F im_nice &lt;- TRUE # NOT !im_tall # I&#39;m NOT tall = FALSE ## [1] FALSE # AND im_nice &amp; im_short ## [1] FALSE im_nice &amp; im_tall ## [1] TRUE # OR im_nice | im_short ## [1] TRUE # combine using parentheses (not square brackets or braces) # like BEDMAS - perform what&#39;s in () brackets first (im_nice | im_short) &amp; im_tall ## [1] TRUE 1 R Programming Basics Quiz 1 link: https://forms.gle/HWTH5TR7ThCSD79k9 3.4 Practice ** Note: feel free to use fake values for the following problem. Body Mass Index (BMI) can be used to screen for weight categories that may lead to health problems. The formula is BMI = \\(\\frac{weight\\left(kg\\right)}{height\\left(m\\right)^2}\\). BMI ranges are underweight (under 18.5 kg/m2), normal weight (18.5 to 25), overweight (25 to 30), and obese (over 30). a) Define a variable and assign the value of your weight to it. (Note: kg = lb/2.205) b) Define a variable and assign the value of your height to it. (Note: m = inches/39.37) c) Calculate your BMI. Assign the value to a variable. d) Print it with 3 significant digits. e) In 2013, a new formula for BMI that accounts for the distortions of the traditional BMI formula for shorter and taller individuals was proposed by Nick Trefethen, Professor of numerical analysis at Oxford University. (source: link). The new formula is BMI = 1.3*weight(kg)/height(m)^2.5. What is your BMI now? f) Print the statement My BMI is ___. to the console. g) Use a relational operator to check whether your BMI is not underweight? h) Use relational operators AND logical operators to check whether your BMI is in the normal range. Solution # 1.1 BMI practice solution # a) my_weight &lt;- 65 #kg # b) my_height &lt;- 1.80 #m # c) my_BMI &lt;- my_weight/my_height^2 my_BMI ## [1] 20.06173 # d) print(my_BMI, digits = 3) ## [1] 20.1 # e) my_new_BMI &lt;- 1.3*my_weight/my_height^2.5 # f) statement &lt;- sprintf(&quot;My BMI is %s.&quot;, round(my_BMI,digits = 1)) #round to 1 decimal place print(statement) ## [1] &quot;My BMI is 20.1.&quot; # g) my_BMI &gt;= 18.5 # am i not underweight? T/F ## [1] TRUE # h) # usually we&#39;d do 18.5 &lt;= my_BMI &lt;= 25 but you can&#39;t have multiple relational operators on the same line of code without Boolean ones my_BMI &gt;= 18.5 &amp; my_BMI &lt;= 25 ## [1] TRUE "],["data-structures.html", "4 Data Structures 4.1 Vectors 4.2 Data Frames 4.3 Practice 4.4 Lists 4.5 Factors 4.6 Matrices", " 4 Data Structures Objective: Learn how to work with vectors and data frames in R. We will cover: vector creation using c() Positive and negative indexing using [] Vector functions (mean, sd, sort, max, min, etc) Dataframe (), how to access data [rows, cols], subset, and important functions ** Note: info about list(), factor(), and matrix() are included in this tutorial but we will not cover these structures together Data structure: - organization, management, and storage format for data - enables efficient access and modification Based on this tutorial: http://www.sthda.com/english/wiki/easy-r-programming-basics#basic-arithmetic-operations 4.1 Vectors A vector in R is a combination of multiple values of the same data type (numeric, character or logical) in the same object/variable each value is called an element also called array created using the function c() (for concatenate) We can give a name to the elements of a vector using the function names() # Store cell types in a character vector cell.types &lt;- c(&quot;neutrophil&quot;, &quot;NK&quot;, &quot;macrophage&quot;, &quot;B-cell&quot;) # create cell.types # print ## [1] &quot;neutrophil&quot; &quot;NK&quot; &quot;macrophage&quot; &quot;B-cell&quot; # Store the expression level in a numeric vector (arbitrary) expr_lvls &lt;- c(78,20,53,0) expr_lvls ## [1] 78 20 53 0 # Store whether it is from the myeloid lineage is_myeloid &lt;- c(T, F, T, F) is_myeloid ## [1] TRUE FALSE TRUE FALSE # Name expresson levels by cell type names(expr_lvls) &lt;- cell.types expr_lvls ## neutrophil NK macrophage B-cell ## 78 20 53 0 # conversely, can create named vector as follows: expr_lvls &lt;- c(neutrophil = 78, NK = 20, macrophage = 53, B_cell = 0) unname(expr_lvls) #unname ## [1] 78 20 53 0 # combine vectors c(expr_lvls, cell.types) #converts mixed data types to the same one based on data type hierarchies, character &gt; numeric &gt; logical ## neutrophil NK macrophage B_cell ## &quot;78&quot; &quot;20&quot; &quot;53&quot; &quot;0&quot; &quot;neutrophil&quot; &quot;NK&quot; ## ## &quot;macrophage&quot; &quot;B-cell&quot; Case of missing values - Missing information are represented by NA. expr_lvls &lt;- c(neutrophil = 78, NK = 20, macrophage = 53, B_cell = NA) is.na(expr_lvls) # note: an example of vectorization where you can apply a function to a vector as if it were just one value ## neutrophil NK macrophage B_cell ## FALSE FALSE FALSE TRUE Other ways to create vectors: * using : operator * using seq() function (create a sequence) # Make a numeric vector using : 1:4 ## [1] 1 2 3 4 # Specify first and last element using seq() seq(from = 1.2, to = 3, by=0.2) # specify step size ## [1] 1.2 1.4 1.6 1.8 2.0 2.2 2.4 2.6 2.8 3.0 seq(1, 5, length.out=4) # specify length of the vector ## [1] 1.000000 2.333333 3.666667 5.000000 Access elements of a vector Elements of a vector can be accessed using vector indexing the vector used for indexing can be logical, integer or character vector Using integer vector as index Vector index in R starts from 1 (unlike most programming languages where index start from 0) We can use a vector of integers as index to access specific elements We can use negative integers to return all elements except that those specified x &lt;- 11:20 x[3] ## [1] 13 x[c(2, 4)] # access 2nd and 4th element ## [1] 12 14 x[-1] # access all but 1st element ## [1] 12 13 14 15 16 17 18 19 20 # x[c(2, -4)] # ERROR: cannot mix positive and negative integers x[c(2.4, 3.54)] # real numbers are truncated to integers ## [1] 12 13 NOTE: I am not saving my output into a variable so it does not modify the original x variable Using logical vector as index - When we use a logical vector for indexing, the position where the logical vector is TRUE is returned intensity_lvl &lt;- c(322, 39, 234, 890) intensity_lvl[c(TRUE, FALSE, FALSE, TRUE)] #length of logical vector must match length of vector ## [1] 322 890 THRESHOLD &lt;- 300 intensity_lvl[intensity_lvl &lt; THRESHOLD] # filtering vectors based on conditions ## [1] 39 234 intensity_lvl[intensity_lvl &gt; 0] ## [1] 322 39 234 890 Using character vector as index - This type of indexing is useful when dealing with named vectors expr_lvls &lt;- c(neutrophil = 78, NK = 20, macrophage = 53, B_cell = NA) expr_lvls[&quot;neutrophil&quot;] ## neutrophil ## 78 expr_lvls[c(&quot;neutrophil&quot;, &quot;NK&quot;)] ## neutrophil NK ## 78 20 Modify and delete vectors - access specific elements and modify them using the assignment operator - perform arithmetic and logical operations on the vector - delete using NULL keyword x &lt;- 1:4 # modify the first element x[1] &lt;- 15 x ## [1] 15 2 3 4 # arithmetic operator x + 2 ## [1] 17 4 5 6 x/x ## [1] 1 1 1 1 # logical operator !c(T,F) ## [1] FALSE TRUE # delete vector x &lt;- NULL x[1] ## NULL Vector functions Some useful functions are: x &lt;- seq(10, 100, by = 10) max(x) # Get the maximum value of x ## [1] 100 min(x) # Get the minimum value of x ## [1] 10 range(x) # Get the range of x (min, max) ## [1] 10 100 length(x) # Get the number of elements in x ## [1] 10 sum(x) # Get the total of the elements in x ## [1] 550 prod(x) # Get the product of the elements in x ## [1] 3.6288e+16 mean(x) # The mean value of the elements in x - sum(x)/length(x) ## [1] 55 sd(x) # Standard deviation of x ## [1] 30.2765 var(x) # Variance of x ## [1] 916.6667 sort(x) # Sort the element of x in ascending order ## [1] 10 20 30 40 50 60 70 80 90 100 Note: if you want to exclude NAs, most of these functions have a na.rm argument. 4.2 Data Frames Data frames is a table (matrix-like 2D object) where columns can have different vector types (numeric, character, logical) Arguably the most useful data structure in R Create a data frame using data.frame(), specifying columns Some important functions dim(), nrow() and ncol() - return the dimensions, number of rows and columns summary(), str() - give you information like stats, dimensions, data types, etc in your data frame rownames() - retrieve or set row names of a matrix-like object colnames() - retrieve or set column names of a matrix-like object cbind() - combine R objects by columns rbind() - combine R objects by rows t() - transpose the matrix (columns become rows and vice-versa) rowSums() and colSums() functions: Compute the total of each row and the total of each column (when data frame is numeric) cells_df &lt;- data.frame( Name = cell.types, Expression = expr_lvls, myeloid_lineage = is_myeloid, Intensity1 = c(258, NA, 185, 290), stringsAsFactors = F # set this to F for now, think of factors levels of for vectors ) cells_df ## Name Expression myeloid_lineage Intensity1 ## neutrophil neutrophil 78 TRUE 258 ## NK NK 20 FALSE NA ## macrophage macrophage 53 TRUE 185 ## B_cell B-cell NA FALSE 290 # Check if it&#39;s a data frame is.data.frame(cells_df) ## [1] TRUE # Get dimensions dim(cells_df) ## [1] 4 4 # Get column names colnames(cells_df) ## [1] &quot;Name&quot; &quot;Expression&quot; &quot;myeloid_lineage&quot; &quot;Intensity1&quot; # Rename rows rownames(cells_df) &lt;- paste(&quot;Cell&quot;, 1:nrow(cells_df), sep =&quot;.&quot;) cells_df ## Name Expression myeloid_lineage Intensity1 ## Cell.1 neutrophil 78 TRUE 258 ## Cell.2 NK 20 FALSE NA ## Cell.3 macrophage 53 TRUE 185 ## Cell.4 B-cell NA FALSE 290 # Add column/row # NOTE AGAIN: if I don&#39;t save my code into a variable, it does not modify the original dataframe cbind(cells_df, Intensity2 = c(3315, 458, 5643, 100)) ## Name Expression myeloid_lineage Intensity1 Intensity2 ## Cell.1 neutrophil 78 TRUE 258 3315 ## Cell.2 NK 20 FALSE NA 458 ## Cell.3 macrophage 53 TRUE 185 5643 ## Cell.4 B-cell NA FALSE 290 100 rbind(cells_df, Cell.5 = c(&quot;mast cell&quot;, NA, T, 452)) ## Name Expression myeloid_lineage Intensity1 ## Cell.1 neutrophil 78 TRUE 258 ## Cell.2 NK 20 FALSE &lt;NA&gt; ## Cell.3 macrophage 53 TRUE 185 ## Cell.4 B-cell &lt;NA&gt; FALSE 290 ## Cell.5 mast cell &lt;NA&gt; TRUE 452 Access and subset a data frame Access columns and rows by indexing by name and by location Format is dataframe[row,column] # think of your rows and columns as vectors Access columns by dollar sign $ # Access the data in &#39;name&#39; column cells_df[,1] # index by location ## [1] &quot;neutrophil&quot; &quot;NK&quot; &quot;macrophage&quot; &quot;B-cell&quot; cells_df[,&quot;Name&quot;] # index by name of column ## [1] &quot;neutrophil&quot; &quot;NK&quot; &quot;macrophage&quot; &quot;B-cell&quot; cells_df$Name # access using $ ## [1] &quot;neutrophil&quot; &quot;NK&quot; &quot;macrophage&quot; &quot;B-cell&quot; # Access the data for Cell 2 cells_df[&quot;Cell.2&quot;,] ## Name Expression myeloid_lineage Intensity1 ## Cell.2 NK 20 FALSE NA Subset using logical expressions, positive indexing (specifiy which columns/rows to keep), and negative indexing to exclude columns/rows Subset using the subset() function If you subset using vectors with more than one element, it returns a dataframe, if not it will return a vector Modify the same way as vectors (specify which rows/columns value to access and use assignment to assign new values) # Subset by selecting first 3 rows (both lines of code do the same thing) cells_df[c(1,2,3), ] ## Name Expression myeloid_lineage Intensity1 ## Cell.1 neutrophil 78 TRUE 258 ## Cell.2 NK 20 FALSE NA ## Cell.3 macrophage 53 TRUE 185 cells_df[1:3, ] ## Name Expression myeloid_lineage Intensity1 ## Cell.1 neutrophil 78 TRUE 258 ## Cell.2 NK 20 FALSE NA ## Cell.3 macrophage 53 TRUE 185 # Subset by using character vector parameters &lt;- c(&quot;Expression&quot;, &quot;Intensity1&quot;) cells_df2 &lt;- cells_df[,parameters] log2(cells_df2) # perform functions depending on data type ## Expression Intensity1 ## Cell.1 6.285402 8.011227 ## Cell.2 4.321928 NA ## Cell.3 5.727920 7.531381 ## Cell.4 NA 8.179909 # log2(cells_df) #ERROR: log2 only works when all columns numeric # Subset by selecting the rows that meet the condition (both lines of code do the same thing) cells_df[cells_df$Expression &gt;= 25, ] ## Name Expression myeloid_lineage Intensity1 ## Cell.1 neutrophil 78 TRUE 258 ## Cell.3 macrophage 53 TRUE 185 ## NA &lt;NA&gt; NA NA NA subset(cells_df, subset = Expression &gt;= 25) ## Name Expression myeloid_lineage Intensity1 ## Cell.1 neutrophil 78 TRUE 258 ## Cell.3 macrophage 53 TRUE 185 # Reassign all NA to 0 cells_df[is.na(cells_df)] &lt;- 0 # Can add and remove columns using $ cells_df$Intensity2 &lt;- c(3315, 458, 5643, 100) # add column, alternative to cbind() cells_df ## Name Expression myeloid_lineage Intensity1 Intensity2 ## Cell.1 neutrophil 78 TRUE 258 3315 ## Cell.2 NK 20 FALSE 0 458 ## Cell.3 macrophage 53 TRUE 185 5643 ## Cell.4 B-cell 0 FALSE 290 100 cells_df$Intensity2 &lt;- NULL # remove column 4.3 Practice You are gathering information about your family members (alternatively, your friends or coworkers). a) Make a vector of their names. b) Who is the first person you wrote down? (i.e. Get the first element) c) Make a vector of their ages (in same order as part a)). d) Make a vector if theyre a kid or not (TRUE/FALSE). e) Make a data frame of your family members with column names: Name, Age, Is_Kid. f) Sort their names by alphabetical order. The output should be saved to a data frame variable. (Look this up if you dont know how to!) g) Subset your data frame so only rows of the members that are children shows (do not save as variable). h) Subset your data frame so only rows of the members that are older than 20 years old show (do not save as variable). i) Add 1 to the ages of all your members in one line of code. j) Remove the Is_Kid column. Solution: # a) Make a vector using c() names &lt;- c(&quot;Tinky Winky&quot;, &quot;Dipsy&quot;, &quot;Laa Laa&quot;, &quot;Po&quot;) # b) Use positive indexing names[1] ## [1] &quot;Tinky Winky&quot; # c) Make a vector using c() ages &lt;- c(21, 10, 10, 2) # d) Make a logical vector using c() is_kid &lt;- c(F,T,T,T) # e) Make a data frame using data.frame() family &lt;- data.frame(Name = names, Age = ages, Is_Kid = is_kid) family ## Name Age Is_Kid ## 1 Tinky Winky 21 FALSE ## 2 Dipsy 10 TRUE ## 3 Laa Laa 10 TRUE ## 4 Po 2 TRUE # f) https://www.r-bloggers.com/r-sorting-a-data-frame-by-the-contents-of-a-column/ sorted_family &lt;- family[order(family$Name),] # g) Logical vector or subset() sorted_family[sorted_family$Is_Kid,] ## Name Age Is_Kid ## 2 Dipsy 10 TRUE ## 3 Laa Laa 10 TRUE ## 4 Po 2 TRUE subset(sorted_family, subset = Is_Kid) ## Name Age Is_Kid ## 2 Dipsy 10 TRUE ## 3 Laa Laa 10 TRUE ## 4 Po 2 TRUE # h) subset using logical vector sorted_family[sorted_family$Age &gt; 20,] ## Name Age Is_Kid ## 1 Tinky Winky 21 FALSE subset(sorted_family, subset = Age &gt; 20) ## Name Age Is_Kid ## 1 Tinky Winky 21 FALSE # i) modify the Age column only sorted_family$Age &lt;- sorted_family$Age + 1 # j) Using negative indexing or assigning column to NULL sorted_family$Is_Kid &lt;- NULL # Or sorted_family &lt;- sorted_family[, - which (colnames(sorted_family) == &quot;Is_Kid&quot;)] 4.4 Lists A list is another data structure It is an ordered collection of objects, which can be vectors, matrices, data frames, etc. In other words, a list can contain all kind of R objects. List elements can be accessed by $Name_of_Element or [[index_of_element]] # Create a list # Elements can be any type and structure, including vectors and data frames my_family &lt;- list( mother = &quot;Veronique&quot;, father = &quot;Michel&quot;, sisters = c(&quot;Alicia&quot;, &quot;Monica&quot;), sister_age = c(12, 22) ) # Print my_family ## $mother ## [1] &quot;Veronique&quot; ## ## $father ## [1] &quot;Michel&quot; ## ## $sisters ## [1] &quot;Alicia&quot; &quot;Monica&quot; ## ## $sister_age ## [1] 12 22 # Names of elements in the list names(my_family) ## [1] &quot;mother&quot; &quot;father&quot; &quot;sisters&quot; &quot;sister_age&quot; # Number of elements in the list length(my_family) ## [1] 4 # Subset a list - select element by its name or its index # Select by name (1/2) my_family$father ## [1] &quot;Michel&quot; # Select by name (2/2) my_family[[&quot;father&quot;]] ## [1] &quot;Michel&quot; # Select a specific element of a component # select the first ([1]) element of my_family[[3]] my_family[[&quot;sisters&quot;]][1] ## [1] &quot;Alicia&quot; # Add to list my_family$brother &lt;- &quot;Toby&quot; 4.5 Factors Factor variables represent categories or groups in your data. The function factor() can be used to create a factor variable. R orders factor levels alphabetically, so if you want to redefine the order, do it in the factor() function call # Create a factor variable friend_groups &lt;- factor(c(1, 2, 1, 2)) friend_groups ## [1] 1 2 1 2 ## Levels: 1 2 # Get group names (or levels) levels(friend_groups) ## [1] &quot;1&quot; &quot;2&quot; # Change levels levels(friend_groups) &lt;- c(&quot;best_friend&quot;, &quot;not_best_friend&quot;) friend_groups ## [1] best_friend not_best_friend best_friend not_best_friend ## Levels: best_friend not_best_friend # Change the order of levels friend_groups &lt;- factor(friend_groups, levels = c(&quot;not_best_friend&quot;, &quot;best_friend&quot;)) # Print friend_groups ## [1] best_friend not_best_friend best_friend not_best_friend ## Levels: not_best_friend best_friend # Check if friend_groups is a factor is.factor(friend_groups) ## [1] TRUE # Convert a character_vector as a factor as.factor(c(&quot;A&quot;, &quot;B&quot;, &quot;D&quot;)) ## [1] A B D ## Levels: A B D 4.6 Matrices A matrix is a table containing multiple rows and columns of vectors with the same type, which can be either numeric, character or logical. To create easily a matrix, use the function cbind() or rbind() and perform similar functions to data frames Convert to data frame using as.data.frame() # Numeric vectors col1 &lt;- c(5, 6, 7, 8, 9) col2 &lt;- c(2, 4, 5, 9, 8) col3 &lt;- c(7, 3, 4, 8, 7) # Combine the vectors by column my_data &lt;- cbind(col1, col2, col3) my_data ## col1 col2 col3 ## [1,] 5 2 7 ## [2,] 6 4 3 ## [3,] 7 5 4 ## [4,] 8 9 8 ## [5,] 9 8 7 # Change rownames rownames(my_data) &lt;- c(&quot;row1&quot;, &quot;row2&quot;, &quot;row3&quot;, &quot;row4&quot;, &quot;row5&quot;) # Transpose t(my_data) ## row1 row2 row3 row4 row5 ## col1 5 6 7 8 9 ## col2 2 4 5 9 8 ## col3 7 3 4 8 7 # Dimensions ncol(my_data) # Number of columns ## [1] 3 nrow(my_data) # Number of rows ## [1] 5 dim(my_data) # Number of rows and columns ## [1] 5 3 # Subset by positive indexing my_data[2:4, ] # Select row number 2 to 4 ## col1 col2 col3 ## row2 6 4 3 ## row3 7 5 4 ## row4 8 9 8 my_data[c(2,4), ] # rows 2 and 4 but not 3 ## col1 col2 col3 ## row2 6 4 3 ## row4 8 9 8 my_data[, &quot;col2&quot;] # Select by column 2&#39;s name &quot;col2&quot; ## row1 row2 row3 row4 row5 ## 2 4 5 9 8 # Exclude rows/columns by negative indexing my_data[, -1] # Exclude column 1 ## col2 col3 ## row1 2 7 ## row2 4 3 ## row3 5 4 ## row4 9 8 ## row5 8 7 # Perform simple operations on matrice log2(my_data) ## col1 col2 col3 ## row1 2.321928 1.000000 2.807355 ## row2 2.584963 2.000000 1.584963 ## row3 2.807355 2.321928 2.000000 ## row4 3.000000 3.169925 3.000000 ## row5 3.169925 3.000000 2.807355 my_data*3 ## col1 col2 col3 ## row1 15 6 21 ## row2 18 12 9 ## row3 21 15 12 ## row4 24 27 24 ## row5 27 24 21 You may also construct a matrix using the matrix() function mdat &lt;- matrix(data = c(1,2,3, 11,12,13), nrow = 2, byrow = TRUE, dimnames = list(c(&quot;row1&quot;, &quot;row2&quot;), c(&quot;C.1&quot;, &quot;C.2&quot;, &quot;C.3&quot;))) "],["importexport.html", "5 Import/Export 5.1 Export Tables 5.2 Import Tables 5.3 Graphing with base R 5.4 Practice", " 5 Import/Export Objective: - Learn how to import (read.csv(), read.delim()) and export tabular data (write.csv(), write.delim()) - Learn how to plot graphs using base R We will cover: use data sets provided by R how to create a new directory/folder using dir.create() open several graphics windows save plots to file 5.1 Export Tables ** Tips for Preparing Data** first row = column headers (variables) and first column = row names (observations) Row and column names should be unique shouldnt begin with a number no special symbols (except underscore) avoid blank spaces avoid blank rows and comments use the four digit format for date: Good: 01/01/2016. Bad: 01/01/16 In Excel, save your file into .txt (tab-delimited text file) or .csv (comma separated value file) format. Working with txt and csv files - R has built-in datasets that we may use (see datasets with data() command) # Call data into environment with data(&quot;dataset&quot;) # Loading DNase data data(&quot;DNase&quot;) # Get more info using ? # ?DNase # See first 10 rows with head() head(DNase, n = 10) ## Run conc density ## 1 1 0.04882812 0.017 ## 2 1 0.04882812 0.018 ## 3 1 0.19531250 0.121 ## 4 1 0.19531250 0.124 ## 5 1 0.39062500 0.206 ## 6 1 0.39062500 0.215 ## 7 1 0.78125000 0.377 ## 8 1 0.78125000 0.374 ## 9 1 1.56250000 0.614 ## 10 1 1.56250000 0.609 # basic stats with summary() summary(DNase) ## Run conc density ## 10 :16 Min. : 0.04883 Min. :0.0110 ## 11 :16 1st Qu.: 0.34180 1st Qu.:0.1978 ## 9 :16 Median : 1.17188 Median :0.5265 ## 1 :16 Mean : 3.10669 Mean :0.7192 ## 4 :16 3rd Qu.: 3.90625 3rd Qu.:1.1705 ## 8 :16 Max. :12.50000 Max. :2.0030 ## (Other):80 # unique values of a vector with unique() unique(DNase$Run) ## [1] 1 2 3 4 5 6 7 8 9 10 11 ## Levels: 10 &lt; 11 &lt; 9 &lt; 1 &lt; 4 &lt; 8 &lt; 5 &lt; 7 &lt; 6 &lt; 2 &lt; 3 R base functions for exporting/writing/saving data: * write.table() - exporting any tabular data to .txt file * write.csv() - comma separated values,.csv file variations when comma (,) is used as decimal points instead of periods (.): write.csv2() Arguments: - file = absolute/local file paths with name of file - sep = field seperators (sep argument) - character(s), controls the way splits a data table into fields/cells - header = logical for column names - row.names = vector of row names or number/name of column which contains the row names # Create a Data folder dir.create(&quot;Data&quot;) ## Warning in dir.create(&quot;Data&quot;): &#39;Data&#39; already exists # Write data to txt file: tab separated values # sep = &quot;\\t&quot; write.table(DNase, file = &quot;Data/DNase.txt&quot;, sep = &quot;\\t&quot;, row.names = FALSE) #&quot;\\t&quot; means &quot;tab&quot; # Write data to csv files: # decimal point = &quot;.&quot; and value separators = comma (&quot;,&quot;) write.csv(DNase, file = &quot;Data/DNase.csv&quot;) # Write data to csv files: # decimal point = comma (&quot;,&quot;) and value separators = semicolon (&quot;;&quot;) # write.csv2(DNase, file = &quot;DNase.csv&quot;) 5.2 Import Tables R base functions for importing data read.table() - reading any tabular data read.delim() - reading tab-separated value files (.txt) read.csv() - comma separated value files (.csv) variations when comma (,) is used as decimal points: read.delim2(), read.csv2() file = absolute/local file paths with name of file, file.choose() to choose interactively, internet address e.g. http://www.sthda.com/upload/boxplot_format.txt # Read tabular data into R # file.choose() allows you to interactively pick a data file # df &lt;- read.table(file.choose(), header = FALSE, sep = &quot;\\t&quot;, dec = &quot;.&quot;) # Read &quot;comma separated value&quot; files (&quot;.csv&quot;) filename &lt;- &quot;Data/DNase.csv&quot; df &lt;- read.csv(filename, header = TRUE) # Read TAB delimited files df2 &lt;- read.delim(file = &quot;Data/DNase.txt&quot;, header = TRUE, sep = &quot;\\t&quot;, dec = &quot;.&quot;) # Note to save into an object, we must assign to variable! Working with Excel files * openxlsx package * readxl package Note: install libraries/packages in R using install.packages(package_name). Load intro environment before using with library(package_name) Writing Data From R to Excel Files (xls|xlsx) # # install.packages(&quot;openxlsx&quot;) # # library(&quot;openxlsx&quot;) # or require(&quot;openxlsx&quot;) # # Write the first 10 rows in a new workbook # write.xlsx(DNase[1:10,], file = &quot;Data/DNase.xlsx&quot;, sheetName = &quot;DNase 1&quot;, append = FALSE) # # Add a second data set in a new worksheet with first and third column # write.xlsx(DNase[,c(1,3)], file = &quot;Data/DNase.xlsx&quot;, sheetName = &quot;DNase 2&quot;, append = TRUE) Reading data From Excel Files (xls|xlsx) into R # # Use openxlsx package # my_data &lt;- read.xlsx(&quot;Data/DNase.xlsx&quot;, sheetIndex = 1) Using R data format: RDATA and RDS Save/load variables, user-made functions and data Saving objects Save one object to a file: saveRDS(object, file) Save multiple objects to a file: save(data1, data2, file) Save your entire workspace (all objects): save.image() Loading objects readRDS(rds_file), load(RData_file) # # Save a single object to a file # saveRDS(DNase, &quot;Data/DNase.rds&quot;) # # Restore it under a different name # my_data &lt;- readRDS(&quot;Data/DNase.rds&quot;) # # Save multiple objects # save(DNase, my_data, file = &quot;Data/data.RData&quot;) # # To load the data again # load(&quot;Data/data.RData&quot;) # # Saving and restoring your entire workspace: # # Save your workspace # save.image(file = &quot;Data/my_work_space.RData&quot;) # # Load the workspace again # load(&quot;Data/my_work_space.RData&quot;) Consider using readr package * Reading lines from a file: read_lines() * readr functions for writing data: write_tsv(), write_csv() * readr for reading/writing txt|csv files: read_tsv(), read_csv(), etc 5.3 Graphing with base R Now that we can import our data, we can learn how to plot it. The purpose of base R plots is to analyze our data, not as elegant for publication purposes plot() - generic function, meaning it can work with different types of objects - plot() function can be used to plot 2 variables (of equal length) plot(x, y, type=) Arguments x and y = the coordinates of points to plot type = the type of graph to create, possible values: p - points - scatter plot l - lines b - both points and lines c - empty points joined by lines o - overplotted points and lines s and S - stair steps h - histogram-like vertical lines n - does not produce any points or lines main = Title for plot xlab = Title for x axis ylab = Title for y axis You can specify fonts, colors, line styles, axes, reference lines, etc. by adding graphical parameters (cex, col, lwd, etc) Read more: https://www.statmethods.net/advgraphs/parameters.html Combine plots using par() Read more: https://www.statmethods.net/advgraphs/layout.html # You can plot all pairs of variables in one graph plot(DNase) # You can also specify vectors to plot conc &lt;- DNase$conc; dens &lt;- DNase$density plot(x = conc, y = dens, type =&quot;p&quot;) plot(x = conc, y = dens, type =&quot;h&quot;) plot(x = conc, y = dens, type =&quot;s&quot;) # Add title plot(x = conc, y = dens, type =&quot;h&quot;, col = &quot;red&quot;, # colour of line lwd = 3, # width of line xlab = &quot;Conc&quot;, ylab = &quot;Density&quot;, # x, y axis labels main = &quot;ELISA Assay of DNase&quot;) # title for plot Tip: Open graphics windows before calling plot() to view larger plot/several graphs at once Function - Platform In Windows, windows() or win.graph() In Unix, X11() In Mac, quartz() or x11() # windows() x &lt;- seq(-pi,pi, by = 0.1) plot(x, sin(x), main=&quot;The Sine Function&quot;) Plot line graph with regression Linear regression: statistical analysis technique used to determine the extent to which there is a linear relationship between a dependent variable and one or more independent variables create simple regression using lm() or linear model function 2 common parameters: + formula: describes the model with the format Y-var ~ X-var, where Y-var is the dependent variable and X-var is independent variable + data: the variable that contains the dataset summary() is used to find the intercept and coefficients (under Estimate), R^2 and p-value Recall: y = mx + b, where m is c Read more: https://www.r-bloggers.com/r-tutorial-series-simple-linear-regression/ # Plot plot(DNase$conc, y &lt;- DNase$density, type = &quot;p&quot;, # line graph col = &quot;red&quot;, # colour of line lwd = 3, # width of line xlab = &quot;Concentration&quot;, # x axis label ylab = &quot;Density&quot;, # y axis label main = &quot;ELISA assay of DNase&quot;) # title of plot # Make a linear model with the density and concentration variables fit &lt;- lm (density ~ conc, data = DNase) fit ## ## Call: ## lm(formula = density ~ conc, data = DNase) ## ## Coefficients: ## (Intercept) conc ## 0.2949 0.1366 # Get statistics summary(fit) ## ## Call: ## lm(formula = density ~ conc, data = DNase) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.30901 -0.19640 -0.03957 0.19498 0.48056 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.29488 0.02072 14.23 &lt;2e-16 *** ## conc 0.13657 0.00406 33.63 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2181 on 174 degrees of freedom ## Multiple R-squared: 0.8667, Adjusted R-squared: 0.8659 ## F-statistic: 1131 on 1 and 174 DF, p-value: &lt; 2.2e-16 # Add a line to the plot (new layer) abline(fit) # Add text to the plot (new layer) # text() Make a basic histogram of a numeric vector using hist() ref: https://rstudio-pubs-static.s3.amazonaws.com/7953_4e3efd5b9415444ca065b1167862c349.html Histograms: show frequencies for ranges of values hist(DNase$density) Saving to File 1 - Plot by exporting using Export in plot panel (bottom-right pane) or in window menu 2 - Plot by opening a file connection Format: type_of_file(filename) pdf(rplot.pdf): pdf file png(rplot.png): png file jpeg(rplot.jpg): jpeg file postscript(rplot.ps): postscript file bmp(rplot.bmp): bmp file win.metafile(rplot.wmf): windows metafile Note: Use dev.off() to close the connection after plotting # Create 2 vectors with 10 elements/values TEN_Random &lt;- runif(10, 0.0, 1.0) TEN_sequence &lt;- seq(from = 1, to = 30, length.out = 10) # Make the second value missing in y TEN_sequence[2] &lt;- NA # Create a &quot;Plots&quot; directory in your current working directory dir.create(&quot;Plots&quot;) ## Warning in dir.create(&quot;Plots&quot;): &#39;Plots&#39; already exists # Save to png file png(&quot;Plots/plot.png&quot;) # open &quot;device&quot; connection plot(x = TEN_sequence, y = TEN_Random, xlab = &quot;Index&quot;, ylab = &quot;Random values&quot;) # plot dev.off() #close connection ## png ## 2 Create an editable graph from R using ReporteRs package Editable vector graphics can be created and saved in a Microsoft document Read here: http://www.sthda.com/english/wiki/create-an-editable-graph-from-r-software 5.4 Practice The women data set in R gives the average heights and weights for American women aged 30 to 39. a) Print the first 15 rows to the console. (Hint: use the n argument in head() function) b) Create a folder called Data Sets in your current working directory. c) Write the women data frame as a csv file to the Data Sets folder (exclude row names). d) Read this file back into R and assign it to a variable called women.df. e) Plot a histogram of the heights column. f) Find the mean and standard deviation of heights (Recall: vectors tutorial) g) print the variables from f) in a statement The mean and standard deviation of the heights is __ and __ (Hint: use sprintf() or paste() ) h) Plot a scatter plot, where x = height and y = weight. Relabel x and y axes to Height (in) and Weight (lbs) respectively. i) Save f) to a jpeg file. Solution data(&quot;women&quot;) # a) Print using head() head(women, n = 15) ## height weight ## 1 58 115 ## 2 59 117 ## 3 60 120 ## 4 61 123 ## 5 62 126 ## 6 63 129 ## 7 64 132 ## 8 65 135 ## 9 66 139 ## 10 67 142 ## 11 68 146 ## 12 69 150 ## 13 70 154 ## 14 71 159 ## 15 72 164 # b) Create a folder using dir.create() dir.create(&quot;Data Sets&quot;) ## Warning in dir.create(&quot;Data Sets&quot;): &#39;Data Sets&#39; already exists # c) Write to csv using write.csv() write.csv(x = women, file = &quot;Data sets/women.csv&quot;, row.names = F) # d) Read using read.csv() women.df &lt;- read.csv(file = &quot;Data sets/women.csv&quot;) # e) Plot histogram using hist() hist(women.df$height) # f) Find mean using mean() and standard deviation using sd() mean.hts &lt;- mean(women.df$height) sd.hts &lt;- sd(women.df$weight) # g) Print sprintf(&quot;The mean and standard deviation of the heights is %s and %s&quot;, mean.hts, sd.hts) ## [1] &quot;The mean and standard deviation of the heights is 65 and 15.4986942614378&quot; paste(&quot;The mean of the heights is &quot;, mean.hts, &quot; and &quot;, sd.hts, sep = &quot;&quot;) ## [1] &quot;The mean of the heights is 65 and 15.4986942614378&quot; # h) Plot using plot() plot(x=women.df$height, y=women.df$weight, xlab = &quot;Height (in)&quot;, ylab = &quot;Weight (lbs)&quot;, main = &quot;Avg Heights and Weights for American Women 30-39&quot;) # i) Save as jpeg jpeg(filename = &quot;heights_vs_weights.jpeg&quot;) plot(x=women.df$height, y=women.df$weight, xlab = &quot;Height (in)&quot;, ylab = &quot;Weight (lbs)&quot;, main = &quot;Avg Heights and Weights for American Women 30-39&quot;) dev.off() ## png ## 2 "],["graphing-with-ggplot2.html", "6 Graphing with ggplot2 6.1 What is ggplot2? 6.2 Factors 6.3 R Colors", " 6 Graphing with ggplot2 Objective: To learn how to use ggplot2 package for custom visualizations We will cover: Initializing a plot using ggplot() function call geom_ layers and how to save ggplots (gg_save()) Factors This tutorial is based upon a lesson by UofT coders: https://uoftcoders.github.io/studyGroup/lessons/r/ggplot2/lesson/. Check out their sessions! Well use the ToothGrowth data set (comes with R) A full tutorial using this dataset to make ggplot2 graphs can be found here: http://www.sthda.com/english/articles/32-r-graphics-essentials/125-ggplot-cheat-sheet-for-great-customization # Make the data appear in environment # you can still use it without doing this step data(&quot;ToothGrowth&quot;) # Look at the first 6 rows head(ToothGrowth) ## len supp dose ## 1 4.2 VC 0.5 ## 2 11.5 VC 0.5 ## 3 7.3 VC 0.5 ## 4 5.8 VC 0.5 ## 5 6.4 VC 0.5 ## 6 10.0 VC 0.5 # Look at the structure of a data frame (column names and data types) str(ToothGrowth) ## &#39;data.frame&#39;: 60 obs. of 3 variables: ## $ len : num 4.2 11.5 7.3 5.8 6.4 10 11.2 11.2 5.2 7 ... ## $ supp: Factor w/ 2 levels &quot;OJ&quot;,&quot;VC&quot;: 2 2 2 2 2 2 2 2 2 2 ... ## $ dose: num 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 ... # # Learn more about the data # ? ToothGrowth Use base plotting functions to look at data plot(ToothGrowth) # Make a scatter plot of 2 variables plot(x = ToothGrowth$dose, y = ToothGrowth$len, type = &quot;p&quot;, xlab = &quot;Length&quot;, ylab = &quot;Dose&quot;, main = &quot;Tooth Length vs Dose&quot;) # make a histogram of length hist(ToothGrowth$len, xlab = &quot;Length&quot;) But ggplot2 plots are prettier: 6.1 What is ggplot2? the gg in ggplot2 stands for the Grammar of Graphics The idea is that the composition of graphical components in statistical graphics has grammar By controlling that grammar, you can create a set of graphics tailored to your particular needs Starting with the ggplot() function call, each graphical component is added (using +) to the plot as a layer Components of a ggplot: 1. Aesthetics (within brackets of mapping = aes()), where mapping is an argument in ggplot() or geom_ (), examples: x and y position - x, y size of elements - size shape of elements - shape colour of elements - color 2, Elements in a plot are geometric shapes, examples: points - geom_point() lines - geom_line() regression - geom_smooth() boxes - geom_boxplot() bars - geom_bar() text - geom_text() Some of these geometries have their own particular aesthetics. For instance: points have: point shape point size lines have: line type line len bars have: y minimum y maximum fill color outline color text install ggplot2 # Install package # install.packages(&quot;ggplot2&quot;) # Load package into environment library(ggplot2) ## Warning: package &#39;ggplot2&#39; was built under R version 4.1.3 Our first graph? # Initialize ggplot object using ggplot() # If mapping = aes() is not defined, you must supply it in each layer added to the plot # Here, x is the &quot;dose&quot; column and y is the &quot;len&quot; column in ToothGrowth ggplot(ToothGrowth, mapping = aes(x=dose, y=len)) Weve made the structure of our graph, but we need to add a layer to it in order to define what type of graph it is. Lets make a scatterplot: # Add geom_point() to your ggplot() object to visualize points ggplot(ToothGrowth, aes(x=dose, y=len)) + geom_point() 6.2 Factors You can see the dose variable is taken as a continuous variable. This is where factors are important. - Factor variables represent discrete categories or groups in your data. The function factor() can be used to create a factor variable. - R orders factor levels alphabetically, so if you want to redefine the order, do it in the factor() function call. - is.factor() returns TRUE if an object is a factor. # The structure function tells you if a column in a data frame is a factor str(ToothGrowth) ## &#39;data.frame&#39;: 60 obs. of 3 variables: ## $ len : num 4.2 11.5 7.3 5.8 6.4 10 11.2 11.2 5.2 7 ... ## $ supp: Factor w/ 2 levels &quot;OJ&quot;,&quot;VC&quot;: 2 2 2 2 2 2 2 2 2 2 ... ## $ dose: num 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 ... # Convert &quot;dose&quot; from a numeric vector to a factor (continuous to discrete) is.numeric(ToothGrowth$dose) # Is it a numeric vector? Yes ## [1] TRUE ToothGrowth$dose &lt;- factor(ToothGrowth$dose) # Reassign as factor to dataframe levels(ToothGrowth$dose) # Check the levels ## [1] &quot;0.5&quot; &quot;1&quot; &quot;2&quot; # Check whether &quot;supp&quot; column is a factor ToothGrowth$supp # we know it&#39;s a factor because it specifies lvls ## [1] VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC ## [26] VC VC VC VC VC OJ OJ OJ OJ OJ OJ OJ OJ OJ OJ OJ OJ OJ OJ OJ OJ OJ OJ OJ OJ ## [51] OJ OJ OJ OJ OJ OJ OJ OJ OJ OJ ## Levels: OJ VC is.character(ToothGrowth$supp) # Is it a character vector? ## [1] FALSE is.factor(ToothGrowth$supp) # Is it a factor? ## [1] TRUE # Reorder the supp variable so &quot;VC&quot; has greater precedence than &quot;OJ&quot; levels(ToothGrowth$supp) ## [1] &quot;OJ&quot; &quot;VC&quot; factor(ToothGrowth$supp, levels = c(&quot;VC&quot;, &quot;OJ&quot;)) # Note: there is no assignment in this line so we did not modify the data frame ## [1] VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC VC ## [26] VC VC VC VC VC OJ OJ OJ OJ OJ OJ OJ OJ OJ OJ OJ OJ OJ OJ OJ OJ OJ OJ OJ OJ ## [51] OJ OJ OJ OJ OJ OJ OJ OJ OJ OJ ## Levels: VC OJ You can also save the structure of the graph to a variable and then add layers and other attributes to it. Lets do that: # Save ggplot object g &lt;- ggplot(ToothGrowth, aes(x=dose, y=len)) # Add a layer g + geom_point() We can add other layers of graphs to our first graph. Lets add a trend line to our scatterplot: g + geom_point() + geom_smooth() ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; ## `geom_smooth()` using method = &#39;gam&#39; We can also facet our graphs, which means dividing a plot into subplots based on the values of one or more discrete variables. g + geom_point() + geom_smooth() + facet_grid(supp~.) ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; ## `geom_smooth()` using method = &#39;gam&#39; There are lots of ways to organize your facet. See faceting at the bottom of ggplot cheetsheet. Lets say we dont want to facet, but we want to colour the dots depending on the dose of the ToothGrowth: ggplot(ToothGrowth, aes(x=dose, y=len, color=supp)) + geom_point() # equivalent to.. # ggplot(ToothGrowth, aes(x=dose, y=len)) + geom_point(aes(color=supp)) **Specify colours to discrete values - for the variable in aes(color = ___)** ggplot(ToothGrowth, aes(x=dose, y=len)) + geom_point(aes(color = supp)) + scale_color_manual(values = c(VC = &quot;#00AFBB&quot;, OJ = &quot;#E7B800&quot;)) # this layer adds color for the variable specified by the &quot;color&quot; aesthetic We can also change some aesthetic features of the graph. Lets get rid of the color aspect of our structure and change the colour and size of the points: ggplot(ToothGrowth, aes(x=dose, y=len)) + geom_point(color=&quot;steelblue&quot;, size=4) # Note here: The &quot;color&quot; parameter is outside the mapping = aes() parantheses - this means the color is no longer dependent on a variable/column in our data frame We can change many components of our plot. For example, here we can change the labels using individual layers or the labs() layer. We can also change the theme (background color, grid lines, axes font and size, etc). ggplot2 offers themes such as theme_bw() or theme_classic(), but you can make your own using the theme(a) layer. g + geom_point() + ylab(&quot;Tooth Length&quot;) + xlab(&quot;Dose&quot;) + ggtitle(&quot;Effect of Vitamin C dose on tooth length&quot;) + theme_bw() # Alternative code using labs() p &lt;- g + geom_point() + labs(xlab = &quot;Dose&quot;, ylab = &quot;Tooth Length&quot;, title = &quot;Effect of Vitamin C dose on tooth length&quot;) + theme_bw() ** Save using ggsave** # Save last pltext() = &quot;ToothGrowth.png&quot;, plot = p2) What about a bar plot? Lets find out how many ToothGrowth of each dose are in the dataset. ggplot(ToothGrowth, aes(dose)) + geom_bar() Other packages using ggplot2 What about making interactive graphs in R? There is a package called plotly that lets us make our ggplot2 graphs interactive: # install.packages(&quot;plotly&quot;) library(plotly) ## ## Attaching package: &#39;plotly&#39; ## The following object is masked from &#39;package:ggplot2&#39;: ## ## last_plot ## The following object is masked from &#39;package:stats&#39;: ## ## filter ## The following object is masked from &#39;package:graphics&#39;: ## ## layout ## Error in library(plotly): there is no package called &#39;plotly&#39; boxplot &lt;- ggplot(ToothGrowth, aes(dose, len, color = supp)) + geom_boxplot() p = ggplotly(boxplot) ## Warning: The following aesthetics were dropped during statistical transformation: ## y_plotlyDomain ## i This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## i Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? ## Error in eval(expr, envir, enclos): could not find function &quot;ggplotly&quot; p Finally, here is qplot, a way of making super quick scatterplots in R. qplot(dose, len, data = ToothGrowth) ## Warning: `qplot()` was deprecated in ggplot2 3.4.0. 6.3 R Colors hexadecimal to represent color names (#rrggbb), can be interpreted as 0.0 and FF as 1.0 i.e., red= #FF0000 , black=#000000, white = #FFFFFF additionally, 657 built in color names (use the colors() commmand to see all or look at this link: http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf) Read more: https://www.nceas.ucsb.edu/sites/default/files/2020-04/colorPaletteCheatsheet.pToothGrowth ggplot(ToothGrowth, aes(x=dose, y=len)) + geom_boxplot(aes(color = supp)) + scale_color_manual(values = c(VC = &quot;darkorchid1&quot;, OJ = &quot;orange1&quot;)) R colors Use RColorBrewer Use ggsci package for scientific publications - Read more: https://cran.r-project.org/web/packages/ggsci/vignettes/ggsci.html # install.packages(c(&quot;RColorBrewer&quot;, &quot;ggsci&quot;, &quot;scales&quot;)) # Libraries for color palettes library(RColorBrewer) ## Warning: package &#39;RColorBrewer&#39; was built under R version 4.1.3 library(ggsci) # Library for show_col() function library(scales) ## Warning: package &#39;scales&#39; was built under R version 4.1.3 # Use RColorBrewer palettes # View a single RColorBrewer palette by specifying its name display.brewer.pal(n = 8, name = &#39;Dark2&#39;) # Use brewer scales to color discrete values (read more https://ggplot2.tidyverse.org/reference/scale_brewer.html) # Box plot g + geom_boxplot(aes(color = supp)) + scale_color_brewer(palette = &quot;Dark2&quot;) # Scatter plot g + geom_point(aes(color = supp)) + scale_fill_brewer(palette = &quot;Dark2&quot;) # Pick colors from ggsci color palette num_colors &lt;- 9 mypal &lt;- pal_npg(&quot;nrc&quot;, alpha = 0.7)(num_colors) show_col(mypal) "],["statistical-tests.html", "7 Statistical Tests 7.1 Lists 7.2 Statistical Significance 7.3 Checks for Normality 7.4 One-Sample Tests 7.5 Two-Sample Tests 7.6 ANOVA 7.7 Adding p-values to ggplot 7.8 Practice", " 7 Statistical Tests Objective: * To perform most commonly used statistical tests using functions in R This tutorial was based on: http://r-statistics.co/Statistical-Tests-in-R.html We will cover: * ggplot2 refresher * list structure * most commonly used statistical tests (functions) - Check for normal distribution (Shapiro Test) - One Sample t-Test (parametric) and Wilcoxon Signed Rank Test (non-parametric) - Two Sample t-Test and Wilcoxon Rank Sum Test - ANOVA * how to add p-values to ggplot2 using ggpubr package First, load the iris dataset that comes with R. # Make the data appear in environment # you can still use it without doing this step data(&quot;iris&quot;) # Look at the first 6 rows head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa # Look at the structure of a data frame (column names and data types) str(iris) ## &#39;data.frame&#39;: 150 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... # # Learn more about the data # ? iris Review - ggplot2 tutorial: Practice 4.1. ggplot2 Initialize a ggplot of the flower Species on the x-axis and the Sepal.Length on the y-axis for the iris dataset. Make this a boxplot, where the boxes are colored by species. Color boxes using an RColorBrewer palette called Dark2. Add geom_points with size of points set to 1. Use theme_bw(). Add a title Sepal Length of Iris Species. Assign this to a variable called g. Plot g. # Load required libraries library(ggplot2) # library to make plots library(RColorBrewer) #library to pick colors # Initialize plot g &lt;- ggplot(iris, aes(x=Species, y=Sepal.Length))+ # # Add layers using + geom_boxplot(aes(color = Species), outlier.fill = NA)+ #make a boxplot, color by species, remove outliers; scale_color_brewer(palette = &quot;Dark2&quot;)+ #set colors geom_point(size=1)+ #add points, NOTE: replots all values including outliers ggtitle(label = &quot;Sepal Length of Iris Species&quot;)+ #add title theme_bw() #set theme to black and white g # NOTE: you would say &quot;fill&quot; instead of &quot;color&quot; to fill boxes in in aes() and use scale_fill_brewer() instead of scale_color_brewer() # Save plot using ggsave() 7.1 Lists A list is an ordered collection of objects, which can be vectors, matrices, data frames, etc. In other words, a list can contain all kinds of R objects. List elements have a name, index, and value, and can be accessed by $ or [[]] e.g. [[name]] or [[1]] or $name Many functions return lists (e.g. ggplot, statistical tests) - look at environment for overview # Elements in a list have names and value # Element value can be any type and structure of data, including vectors and data frames # Create a list # Note: this example features arbritrary values my_analysis &lt;- list( input_data = iris, #dataframe columns.of.interest = c(&quot;Sepal.Length&quot;, &quot;Petal.Width&quot;), #character vector test = &quot;t.test&quot;, #character p.value = &quot;0.0032&quot; #numeric ) # Print list my_analysis ## $input_data ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5.0 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## 11 5.4 3.7 1.5 0.2 setosa ## 12 4.8 3.4 1.6 0.2 setosa ## 13 4.8 3.0 1.4 0.1 setosa ## 14 4.3 3.0 1.1 0.1 setosa ## 15 5.8 4.0 1.2 0.2 setosa ## 16 5.7 4.4 1.5 0.4 setosa ## 17 5.4 3.9 1.3 0.4 setosa ## 18 5.1 3.5 1.4 0.3 setosa ## 19 5.7 3.8 1.7 0.3 setosa ## 20 5.1 3.8 1.5 0.3 setosa ## 21 5.4 3.4 1.7 0.2 setosa ## 22 5.1 3.7 1.5 0.4 setosa ## 23 4.6 3.6 1.0 0.2 setosa ## 24 5.1 3.3 1.7 0.5 setosa ## 25 4.8 3.4 1.9 0.2 setosa ## 26 5.0 3.0 1.6 0.2 setosa ## 27 5.0 3.4 1.6 0.4 setosa ## 28 5.2 3.5 1.5 0.2 setosa ## 29 5.2 3.4 1.4 0.2 setosa ## 30 4.7 3.2 1.6 0.2 setosa ## 31 4.8 3.1 1.6 0.2 setosa ## 32 5.4 3.4 1.5 0.4 setosa ## 33 5.2 4.1 1.5 0.1 setosa ## 34 5.5 4.2 1.4 0.2 setosa ## 35 4.9 3.1 1.5 0.2 setosa ## 36 5.0 3.2 1.2 0.2 setosa ## 37 5.5 3.5 1.3 0.2 setosa ## 38 4.9 3.6 1.4 0.1 setosa ## 39 4.4 3.0 1.3 0.2 setosa ## 40 5.1 3.4 1.5 0.2 setosa ## 41 5.0 3.5 1.3 0.3 setosa ## 42 4.5 2.3 1.3 0.3 setosa ## 43 4.4 3.2 1.3 0.2 setosa ## 44 5.0 3.5 1.6 0.6 setosa ## 45 5.1 3.8 1.9 0.4 setosa ## 46 4.8 3.0 1.4 0.3 setosa ## 47 5.1 3.8 1.6 0.2 setosa ## 48 4.6 3.2 1.4 0.2 setosa ## 49 5.3 3.7 1.5 0.2 setosa ## 50 5.0 3.3 1.4 0.2 setosa ## 51 7.0 3.2 4.7 1.4 versicolor ## 52 6.4 3.2 4.5 1.5 versicolor ## 53 6.9 3.1 4.9 1.5 versicolor ## 54 5.5 2.3 4.0 1.3 versicolor ## 55 6.5 2.8 4.6 1.5 versicolor ## 56 5.7 2.8 4.5 1.3 versicolor ## 57 6.3 3.3 4.7 1.6 versicolor ## 58 4.9 2.4 3.3 1.0 versicolor ## 59 6.6 2.9 4.6 1.3 versicolor ## 60 5.2 2.7 3.9 1.4 versicolor ## 61 5.0 2.0 3.5 1.0 versicolor ## 62 5.9 3.0 4.2 1.5 versicolor ## 63 6.0 2.2 4.0 1.0 versicolor ## 64 6.1 2.9 4.7 1.4 versicolor ## 65 5.6 2.9 3.6 1.3 versicolor ## 66 6.7 3.1 4.4 1.4 versicolor ## 67 5.6 3.0 4.5 1.5 versicolor ## 68 5.8 2.7 4.1 1.0 versicolor ## 69 6.2 2.2 4.5 1.5 versicolor ## 70 5.6 2.5 3.9 1.1 versicolor ## 71 5.9 3.2 4.8 1.8 versicolor ## 72 6.1 2.8 4.0 1.3 versicolor ## 73 6.3 2.5 4.9 1.5 versicolor ## 74 6.1 2.8 4.7 1.2 versicolor ## 75 6.4 2.9 4.3 1.3 versicolor ## 76 6.6 3.0 4.4 1.4 versicolor ## 77 6.8 2.8 4.8 1.4 versicolor ## 78 6.7 3.0 5.0 1.7 versicolor ## 79 6.0 2.9 4.5 1.5 versicolor ## 80 5.7 2.6 3.5 1.0 versicolor ## 81 5.5 2.4 3.8 1.1 versicolor ## 82 5.5 2.4 3.7 1.0 versicolor ## 83 5.8 2.7 3.9 1.2 versicolor ## 84 6.0 2.7 5.1 1.6 versicolor ## 85 5.4 3.0 4.5 1.5 versicolor ## 86 6.0 3.4 4.5 1.6 versicolor ## 87 6.7 3.1 4.7 1.5 versicolor ## 88 6.3 2.3 4.4 1.3 versicolor ## 89 5.6 3.0 4.1 1.3 versicolor ## 90 5.5 2.5 4.0 1.3 versicolor ## 91 5.5 2.6 4.4 1.2 versicolor ## 92 6.1 3.0 4.6 1.4 versicolor ## 93 5.8 2.6 4.0 1.2 versicolor ## 94 5.0 2.3 3.3 1.0 versicolor ## 95 5.6 2.7 4.2 1.3 versicolor ## 96 5.7 3.0 4.2 1.2 versicolor ## 97 5.7 2.9 4.2 1.3 versicolor ## 98 6.2 2.9 4.3 1.3 versicolor ## 99 5.1 2.5 3.0 1.1 versicolor ## 100 5.7 2.8 4.1 1.3 versicolor ## 101 6.3 3.3 6.0 2.5 virginica ## 102 5.8 2.7 5.1 1.9 virginica ## 103 7.1 3.0 5.9 2.1 virginica ## 104 6.3 2.9 5.6 1.8 virginica ## 105 6.5 3.0 5.8 2.2 virginica ## 106 7.6 3.0 6.6 2.1 virginica ## 107 4.9 2.5 4.5 1.7 virginica ## 108 7.3 2.9 6.3 1.8 virginica ## 109 6.7 2.5 5.8 1.8 virginica ## 110 7.2 3.6 6.1 2.5 virginica ## 111 6.5 3.2 5.1 2.0 virginica ## 112 6.4 2.7 5.3 1.9 virginica ## 113 6.8 3.0 5.5 2.1 virginica ## 114 5.7 2.5 5.0 2.0 virginica ## 115 5.8 2.8 5.1 2.4 virginica ## 116 6.4 3.2 5.3 2.3 virginica ## 117 6.5 3.0 5.5 1.8 virginica ## 118 7.7 3.8 6.7 2.2 virginica ## 119 7.7 2.6 6.9 2.3 virginica ## 120 6.0 2.2 5.0 1.5 virginica ## 121 6.9 3.2 5.7 2.3 virginica ## 122 5.6 2.8 4.9 2.0 virginica ## 123 7.7 2.8 6.7 2.0 virginica ## 124 6.3 2.7 4.9 1.8 virginica ## 125 6.7 3.3 5.7 2.1 virginica ## 126 7.2 3.2 6.0 1.8 virginica ## 127 6.2 2.8 4.8 1.8 virginica ## 128 6.1 3.0 4.9 1.8 virginica ## 129 6.4 2.8 5.6 2.1 virginica ## 130 7.2 3.0 5.8 1.6 virginica ## 131 7.4 2.8 6.1 1.9 virginica ## 132 7.9 3.8 6.4 2.0 virginica ## 133 6.4 2.8 5.6 2.2 virginica ## 134 6.3 2.8 5.1 1.5 virginica ## 135 6.1 2.6 5.6 1.4 virginica ## 136 7.7 3.0 6.1 2.3 virginica ## 137 6.3 3.4 5.6 2.4 virginica ## 138 6.4 3.1 5.5 1.8 virginica ## 139 6.0 3.0 4.8 1.8 virginica ## 140 6.9 3.1 5.4 2.1 virginica ## 141 6.7 3.1 5.6 2.4 virginica ## 142 6.9 3.1 5.1 2.3 virginica ## 143 5.8 2.7 5.1 1.9 virginica ## 144 6.8 3.2 5.9 2.3 virginica ## 145 6.7 3.3 5.7 2.5 virginica ## 146 6.7 3.0 5.2 2.3 virginica ## 147 6.3 2.5 5.0 1.9 virginica ## 148 6.5 3.0 5.2 2.0 virginica ## 149 6.2 3.4 5.4 2.3 virginica ## 150 5.9 3.0 5.1 1.8 virginica ## ## $columns.of.interest ## [1] &quot;Sepal.Length&quot; &quot;Petal.Width&quot; ## ## $test ## [1] &quot;t.test&quot; ## ## $p.value ## [1] &quot;0.0032&quot; # Names of elements in the list names(my_analysis) ## [1] &quot;input_data&quot; &quot;columns.of.interest&quot; &quot;test&quot; ## [4] &quot;p.value&quot; # Number of elements in the list length(my_analysis) ## [1] 4 ## Access the list # select element by its name or its index # Select by name (1/2) my_analysis$p.value ## [1] &quot;0.0032&quot; # Select by name (2/2) my_analysis[[&quot;p.value&quot;]] ## [1] &quot;0.0032&quot; # Select by index my_analysis[[4]] ## [1] &quot;0.0032&quot; # select the first ([1]) element of my_analysis[[2]] my_analysis[[&quot;columns.of.interest&quot;]][1] # equivalent to: my_analysis$columns.of.interest[1] or my_analysis[[2]][1] ## [1] &quot;Sepal.Length&quot; # Add to list #or modify using assignment my_analysis[[&quot;is.significant&quot;]] &lt;- TRUE 7.2 Statistical Significance We define our significance level (usually p &lt; 0.05) When p &lt; 0.05, we reject our null hypothesis and accept the alternative hypothesis mentioned in your R codes output Note: To get more examples, use function example(); Usage: example(t.test) 7.3 Checks for Normality Normal distribution (also called Gaussian) is a type of distribution where - continuous data follows a bell-shaped curve - the central peak represents the mean - the probabilities for values away from mean taper off equally in both directions use parametric tests on normally distributed data test using Shapiro Test or Q-Q plots (quantile-quantile plots) 7.3.1 Shapiro Test To test if a sample follows a normal distribution Null hypothesis: the data are normally distributed * p &gt; 0.05 #normally distributed * p &lt; 0.05 #not normally distributed # Shapiro-Wilk normality test for Petal.Length shapiro.test(iris$Petal.Length) # =&gt; p &lt; 0.05 # not normally distributed ## ## Shapiro-Wilk normality test ## ## data: iris$Petal.Length ## W = 0.87627, p-value = 7.412e-10 # Shapiro-Wilk normality test for Petal.Width shapiro.test(iris$Petal.Width) ## ## Shapiro-Wilk normality test ## ## data: iris$Petal.Width ## W = 0.90183, p-value = 1.68e-08 7.4 One-Sample Tests Null hypothesis: sample mean is equal to estimate/mu * p &lt; 0.05 #means are different One Sample t-test parametric test used to test if the mean of a sample from a normal distribution could reasonably be a specific value t.test(x = iris$Petal.Length, mu=4) # testing if mean of x could be ## ## One Sample t-test ## ## data: iris$Petal.Length ## t = -1.679, df = 149, p-value = 0.09525 ## alternative hypothesis: true mean is not equal to 4 ## 95 percent confidence interval: ## 3.473185 4.042815 ## sample estimates: ## mean of x ## 3.758 # Note: in example, I&#39;m using data that&#39;s not normally distributed note that the 95% confidence interval range includes the value 4 within its range. So, it is ok to say the mean of x is 10 One Sample Wilcoxon Signed Rank Test alternative to t-Test when data is not normally distributed # run test wilcox.test(iris$Petal.Length, mu=20, conf.int = TRUE) ## ## Wilcoxon signed rank test with continuity correction ## ## data: iris$Petal.Length ## V = 0, p-value &lt; 2.2e-16 ## alternative hypothesis: true location is not equal to 20 ## 95 percent confidence interval: ## 3.350008 4.150086 ## sample estimates: ## (pseudo)median ## 3.650033 Note: statisical testing prints result to console, but can also be saved in a list object. # Store the output in the &quot;result&quot; variable result &lt;- t.test(x = iris$Petal.Length, mu=4) # Extract from list - Get the p-value result$p.value #alternatively, result[[&quot;p.value&quot;]] ## [1] 0.09525381 7.5 Two-Sample Tests Null hypothesis: there is no difference in means of x and y * p &lt; 0.05 #means are different Two Sample t-Test and Wilcoxon Rank Sum Test - compare the mean of 2 samples using t.test() and wilcox.test() # two sample t-test t.test(x = iris$Petal.Length, y = iris$Petal.Width) ## ## Welch Two Sample t-test ## ## data: iris$Petal.Length and iris$Petal.Width ## t = 16.297, df = 202.69, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 2.249107 2.868227 ## sample estimates: ## mean of x mean of y ## 3.758000 1.199333 # two sample wilcoxin test wilcox.test(x = iris$Petal.Length, y = iris$Petal.Width) ## ## Wilcoxon rank sum test with continuity correction ## ## data: iris$Petal.Length and iris$Petal.Width ## W = 19349, p-value &lt; 2.2e-16 ## alternative hypothesis: true location shift is not equal to 0 Use paired = TRUE for 1-to-1 comparison of observations x and y should have the sample length # t.test(x, y, paired = TRUE) # when observations are paired, use &#39;paired&#39; argument. # wilcox.test(x, y, paired = TRUE) # both x and y are assumed to have similar shapes 7.6 ANOVA One-way analysis of variance (ANOVA), also known as one-factor ANOVA, is an extension of independent two-samples t-test for comparing means in a situation where there are more than two groups parametric test Computes the common variance, the variance between sample means, and the F-statistic with these two values Read more: http://www.sthda.com/english/wiki/one-way-anova-test-in-r In the iris dataset, there are 3 species (the factor), so we could compare Petal.Width across the groups use aov() to compute ANOVA and anova() of that output to summarize model # Compute the analysis of variance # The first argument is a formula: name_of_variable ~ factor anova_model &lt;- aov(Petal.Width ~ Species, data = iris) # Summary of the analysis anova_summ &lt;- anova(anova_model) anova_summ ## Analysis of Variance Table ## ## Response: Petal.Width ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Species 2 80.413 40.207 960.01 &lt; 2.2e-16 *** ## Residuals 147 6.157 0.042 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # Get p-value anova_summ$`Pr(&gt;F)` ## [1] 4.169446e-85 NA Tukey multiple pairwise-comparisons The ANOVA test tells us that the means between at least one pair is significant. To see which one(s) is significant, we can do post-hoc Tukey HSD (Tukey Honest Significant Differences) for performing multiple pairwise-comparison between the means of groups. The function TukeyHSD() takes the fitted ANOVA as an argument. The output is a table with all pairwise combinations in your factor. TukeyHSD(anova_model) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = Petal.Width ~ Species, data = iris) ## ## $Species ## diff lwr upr p adj ## versicolor-setosa 1.08 0.9830903 1.1769097 0 ## virginica-setosa 1.78 1.6830903 1.8769097 0 ## virginica-versicolor 0.70 0.6030903 0.7969097 0 Alternatively, we could also perform multiple t-tests and adjust p-values by different methods pairwise.t.test(x = iris$Petal.Width, g = iris$Species, p.adjust.method = &quot;fdr&quot;) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: iris$Petal.Width and iris$Species ## ## setosa versicolor ## versicolor &lt;2e-16 - ## virginica &lt;2e-16 &lt;2e-16 ## ## P value adjustment method: fdr pairwise.wilcox.test(x = iris$Petal.Width, g = iris$Species, p.adjust.method = &quot;fdr&quot;) ## ## Pairwise comparisons using Wilcoxon rank sum test with continuity correction ## ## data: iris$Petal.Width and iris$Species ## ## setosa versicolor ## versicolor &lt;2e-16 - ## virginica &lt;2e-16 &lt;2e-16 ## ## P value adjustment method: fdr If you have an object with p-values, you can also perform p.adjust(), read more about the p-adjust function: https://stat.ethz.ch/R-manual/R-devel/library/stats/html/p.adjust.html 7.7 Adding p-values to ggplot using ggpubr package ggpubr R package for an easy ggplot2-based data visualization # # Install the latest version from GitHub as follow (recommended): # install.packages(&quot;devtools&quot;) # devtools::install_github(&quot;kassambara/ggpubr&quot;) # # Or, install from CRAN as follow: # install.packages(&quot;ggpubr&quot;) # Load ggpubr as follow: library(&quot;ggpubr&quot;) # Get the ggplot object made at the beginning of this tutorial g # Get the unique values in Species levels(iris$Species) # unique(iris$Species) ## [1] &quot;setosa&quot; &quot;versicolor&quot; &quot;virginica&quot; # Make a list of Species comparisons comparisons &lt;- list(c(&quot;setosa&quot;,&quot;versicolor&quot;), c(&quot;setosa&quot;, &quot;virginica&quot;), c(&quot;versicolor&quot;, &quot;virginica&quot;)) # Alternative code for line above: no &quot;hard-coding&quot; # elements &lt;- levels(iris$Species) # comparisons &lt;- gtools::combinations(n=length(elements),r=2,v=elements, repeats.allowed=F) # comparisons &lt;- split(comparisons, seq(nrow(comparisons))) # Add stats_compare_means() from ggpubr to your ggplot g + stat_compare_means(method=&quot;t.test&quot;, comparisons = comparisons) Other tests - Read more from this tutorial here: http://r-statistics.co/Statistical-Tests-in-R.html 5. Kolmogorov And Smirnov Test 6. Fishers F-Test 7. Chi Squared Test 5. Kolmogorov And Smirnov Test Which test should I use? https://stats.idre.ucla.edu/other/mult-pkg/whatstat/ 7.8 Practice The women data set in R gives the average heights and weights for American women aged 30 to 39. * Significance level is p&lt;0.05. a) Print the first 10 rows to the console. (Hint: use the n argument in head() function) b) What is the data type of the height column? (Hint: use str() or class()) c) Are the height and weight variables normally distributed? (Hint: use Shapiros test for each) d) Should we use t-test or wilcoxin test on this data? Why? e) Compare the heights to an estimated mean of 66.2 using a one-sample t-test. Is there a significant difference in means? f) Compare the first 6 weights recorded (ie. 1 to 6) to the next 6 (ie. 7 to 12) using a t-test. Is there a significant difference in means? Solution # Load data (you can still use it without this step) data(&quot;women&quot;) # a) Print using head() head(women, n = 10) ## height weight ## 1 58 115 ## 2 59 117 ## 3 60 120 ## 4 61 123 ## 5 62 126 ## 6 63 129 ## 7 64 132 ## 8 65 135 ## 9 66 139 ## 10 67 142 # b) Use class() to get data type class(women$height) # ANSWER: numeric ## [1] &quot;numeric&quot; # c) use Shapiro&#39;s test to test for normality. If p &gt; 0.05, normally distributed shapiro.test(women$height) # p-value = 0.7545 ## ## Shapiro-Wilk normality test ## ## data: women$height ## W = 0.96359, p-value = 0.7545 shapiro.test(women$weight) # p-value = 0.6986 ## ## Shapiro-Wilk normality test ## ## data: women$weight ## W = 0.96036, p-value = 0.6986 # ANSWER: Yes, since p &gt; 0.05 for both variables, the data is normally distributed # d) ANSWER: We could use t-tests because parametric statistical tests is used on normally distributed data. # e) use t.test(), where mu = 66.2 t.test(women$height, mu = 66.2) # p-value = 0.3163 ## ## One Sample t-test ## ## data: women$height ## t = -1.0392, df = 14, p-value = 0.3163 ## alternative hypothesis: true mean is not equal to 66.2 ## 95 percent confidence interval: ## 62.52341 67.47659 ## sample estimates: ## mean of x ## 65 # ANSWER: No, since p &gt; 0.05, there is no significant difference, so the mean of heights is close to 66.2. # f) use t.test() with x,y (two samples) t.test(x = women$weight[1:6], y = women$weight[7:12]) # p-value 0.0003556 ## ## Welch Two Sample t-test ## ## data: women$weight[1:6] and women$weight[7:12] ## t = -5.4053, df = 9.5115, p-value = 0.0003556 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -26.88688 -11.11312 ## sample estimates: ## mean of x mean of y ## 121.6667 140.6667 # ANSWER: Yes, since p &lt; 0.05, there is a significant difference "],["correlation-analysis.html", "8 Correlation Analysis 8.1 Correlation Methods 8.2 Correlation Matrix: 8.3 Practice: Correlation analysis", " 8 Correlation Analysis Objective: To learn how to perform correlation analysis in R We will cover: cor.test(x,y, method) computes the correlation coefficient and significance between two variables cor() creates correlation matrix from a numeric matrix/data frame in corrplot package, cor.mtest() gives p-values and corrplot() plots a graph (i.e. correlogram) of a correlation matrix What is correlation test? Correlation test is used to evaluate the association between two or more continuous (numeric) variables. 8.1 Correlation Methods (Note: Ref for formulas: http://www.sthda.com/english/wiki/correlation-test-between-two-variables-in-r) Pearson correlation: - parametric test, which measures a linear dependence between two variables (x and y) - Correlation coefficient (r) is a value between -1 and 1: -1 - strong negative correlation: x increases, y decreases () 0 - no association between the two variables (x and y) (-) 1 - strong positive correlation: x increases, y increases (/) Kendall tau and Spearman rho are rank-based correlation coefficients (non-parametric) Compute correlation in R ** R functions** cor() computes just correlation coefficient (acts on vectors and data frames) cor.test() computes correlation coefficient and p-value Arguments: x, y = numeric vectors with the same length method = correlation method, e.g. pearson return values: p.value = p-value of the test estimate = the correlation coefficient Here, well use the built-in R data set mtcars for our analysis # Look at the first 6 rows head(mtcars, 6) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 Visualize your data using scatter plots library(&quot;ggpubr&quot;) # ggscatter() creates a scatter plot ggscatter(mtcars, x = &quot;mpg&quot;, y = &quot;wt&quot;, # specify data and aesthetics add = &quot;reg.line&quot;, conf.int = TRUE, # add regression to plot cor.coef = TRUE, cor.method = &quot;pearson&quot;, #label correlation coeffient xlab = &quot;Miles/(US) gallon&quot;, ylab = &quot;Weight (1000 lbs)&quot;) # label axes ## `geom_smooth()` using formula = &#39;y ~ x&#39; Run Pearson correlation test res &lt;- cor.test(mtcars$wt, mtcars$mpg, method = &quot;pearson&quot;) res ## ## Pearson&#39;s product-moment correlation ## ## data: mtcars$wt and mtcars$mpg ## t = -9.559, df = 30, p-value = 1.294e-10 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.9338264 -0.7440872 ## sample estimates: ## cor ## -0.8676594 # In the result above: # t is the t-test statistic value (t = -9.559), # df is the degrees of freedom (df= 30), # p-value is the significance level of the t-test (p-value = 1.29410^{-10}). # conf.int is the confidence interval of the correlation coefficient at 95% (conf.int = [-0.9338, -0.7441]); # sample estimates is the correlation coefficient (Cor.coeff = -0.87). # # Interpretation of result: # - p-value &lt; 0.05 and r = -0.87 &lt; 0. So wt and mpg are significantly correlated and strongly negatively correlated. Recall: result is a list object # &quot;res&quot; is a list object so we can extract values from the result # Extract the p.value res$p.value ## [1] 1.293959e-10 # Extract the correlation coefficient res$estimate ## cor ## -0.8676594 8.2 Correlation Matrix: ** Analyze, Format and Visualize** Read more: http://www.sthda.com/english/wiki/correlation-matrix-a-quick-start-guide-to-analyze-format-and-visualize-a-correlation-matrix-using-r-software Correlation matrix is used to analyze the correlation between multiple variables at the same time (performs pairwise correlation tests) Draw scatter plots using chart.Correlation() The function chart.Correlation() can be used to display multiple charts for a correlation matrix. # # # Install package # # install.packages(&quot;PerformanceAnalytics&quot;) # # Load package into environment # library(&quot;PerformanceAnalytics&quot;) # # Subset data frames (select certain columns) # my_data &lt;- mtcars[, c(1,3,4,5,6,7)] # # Plot scatter plots, histograms and correlation using chart.Correlation() # chart.Correlation(my_data, histogram=TRUE, pch=19) Draw correlogram using corrplot() Correlogram is a graph of correlation matrix # Create correlation matrix M &lt;- cor(mtcars, method = &quot;pearson&quot;) # Print the first 6 rows, round all values to 2 decimal points head(round(M,2)) ## mpg cyl disp hp drat wt qsec vs am gear carb ## mpg 1.00 -0.85 -0.85 -0.78 0.68 -0.87 0.42 0.66 0.60 0.48 -0.55 ## cyl -0.85 1.00 0.90 0.83 -0.70 0.78 -0.59 -0.81 -0.52 -0.49 0.53 ## disp -0.85 0.90 1.00 0.79 -0.71 0.89 -0.43 -0.71 -0.59 -0.56 0.39 ## hp -0.78 0.83 0.79 1.00 -0.45 0.66 -0.71 -0.72 -0.24 -0.13 0.75 ## drat 0.68 -0.70 -0.71 -0.45 1.00 -0.71 0.09 0.44 0.71 0.70 -0.09 ## wt -0.87 0.78 0.89 0.66 -0.71 1.00 -0.17 -0.55 -0.69 -0.58 0.43 use corrplot() to plot the graph of the correlation matrix Arguments corr = correlation matrix method = visualization: circle, square, ellipse, number, shade, color, pie ** many more options to customize: https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html # # Install and load package # install.packages(&quot;corrplot&quot;) # Plot correlogram library(corrplot) ## Warning: package &#39;corrplot&#39; was built under R version 4.1.3 ## corrplot 0.92 loaded corrplot(M, method=&quot;circle&quot;) corrplot(M, method=&quot;color&quot;) # Positive correlations = blue and negative correlations = red # Color intensity and size of the circle are proportional to the correlation coefficients # Display the correlation coefficient: corrplot(M, method=&quot;number&quot;) Use cor.mtest() to make matrix of p-value # Create a list of matrices of p-value, lower confidence interval (CI) and upper CI for a correlation matrix p.mat &lt;- cor.mtest(mtcars) # Get the p-values from the list object p.mat &lt;- p.mat$p # Print the first 6 rows and first 5 columns head(p.mat[, 1:5]) ## mpg cyl disp hp drat ## mpg 0.000000e+00 6.112687e-10 9.380327e-10 1.787835e-07 1.776240e-05 ## cyl 6.112687e-10 0.000000e+00 1.802838e-12 3.477861e-09 8.244636e-06 ## disp 9.380327e-10 1.802838e-12 0.000000e+00 7.142679e-08 5.282022e-06 ## hp 1.787835e-07 3.477861e-09 7.142679e-08 0.000000e+00 9.988772e-03 ## drat 1.776240e-05 8.244636e-06 5.282022e-06 9.988772e-03 0.000000e+00 ## wt 1.293959e-10 1.217567e-07 1.222320e-11 4.145827e-05 4.784260e-06 # Plot correlogram with p-values # Specialized the insignificant value according to the significant level corrplot(M, type=&quot;upper&quot;, p.mat = p.mat, sig.level = 0.01, order=&quot;hclust&quot;) # Note: correlations with p-value &gt; 0.01 are considered as insignificant (i.e. correlation with crosses) # type = upper means show only the upper triangle of the matrix # order = hclust means order the variables by hierarchal clustering 8.3 Practice: Correlation analysis Motor trend car road tests (mtcars) Fuel consumption and 10 additional aspects (variables) of automobile design tested in 1974 are given in an in-built R dataset called mtcars. a) Look at the structure of mtcars. (Use str()) b) Is the first column/variable numeric? c) Are the variables mpg and drat in mtcars normally distributed? (can use shapiro.test()) d) What is the Pearson correlation coefficient and p-value of the correlation between mpg and drat? e) Is the correlation from d) positive or negative? Is it significant? f) Plot a scatter plot of the two variables. Bonus: Add a line for regression. (use plot, ggplot, ggscatter from ggpubr) g) Create a Pearson correlation matrix of mtcars. Assign it to a variable cor_mat h) Create a p-value matrix for the correlation matrix in g). Assign it to a variable p_mat. i) Create a correlogram of the correlation matrix and p-values in g and h using the corrplot package. "],["heatmaps.html", "9 Heatmaps 9.1 Data preparation 9.2 pheatmap() 9.3 Scaling 9.4 Heatmap Colours 9.5 Clustering methods 9.6 Create annotations 9.7 Practice", " 9 Heatmaps Objective: To learn how to draw heatmaps in R using the pheatmap package We will cover: Data preparation: Numeric matrix/data frame as input Log normalization Making heatmaps (base R heatmap() function and pheatmap()) Customization using arguments Scaling Clustering Adding annotations (columns and rows) This session is based upon this tutorial: datanovia.com/en/lessons/heatmap-in-r-static-and-interactive-visualization/ What is a heatmap? - plot to simultaneously visualize clusters of samples and features (i.e. hierarchical clustering) - blocks of high and low values are adjacent - false colored image, where data values are transformed to color scale R Packages/functions for drawing heatmaps * heatmap() [R base function, stats package]: Draws a simple heatmap * heatmap.2() [gplots R package]: Draws an enhanced heatmap compared to the R base function. * pheatmap() [pheatmap R package]: Draws pretty heatmaps and provides more control to change the appearance of heatmaps. * d3heatmap() [d3heatmap R package]: Draws an interactive/clickable heatmap * Heatmap() [ComplexHeatmap R/Bioconductor package]: Draws, annotates and arranges complex heatmaps (very useful for genomic data analysis) 9.1 Data preparation The proteomic data were using today is from Alison Caseys 2018 JCB paper. We will look at the expression of 304 proteins. Note: the column names are in the format Celltype_HormoneTreatment_Replicate where for celltype, BC = basal cell, LP = luminal progenitor, LM = luminal mature for hormone treatment, E = estrogen, EP = estrogen-progesterone Read the tab-delimited text file. # Read into data frame object using read.delim() exp_df &lt;- read.delim(file = &quot;07-Casey-mamm-mouse-proteome-sample.txt&quot;, stringsAsFactors = F) # See the dimensions (row x col) dim(exp_df) ## [1] 304 13 # See the first 6 rows head(exp_df) ## mGeneSym BC_E_1 BC_E_2 BC_EP_1 BC_EP_2 LP_E_1 LP_E_2 LP_EP_1 ## 1 Abcb10 0 0 0 0 1557708 1013752 4221663 ## 2 Abcg2 0 0 2163991 1048502 12987493 7697484 6474732 ## 3 Abhd4 4956153 5124382 13346955 10634977 0 0 0 ## 4 Abhd5 0 0 0 0 1255272 4329562 5741534 ## 5 Acox1 8926818 9756252 7242814 6847158 4069287 6442152 19309447 ## 6 Ada 12920739 9339090 3126248 8926815 45120667 77396731 80759779 ## LP_EP_2 LM_E_1 LM_E_2 LM_EP_1 LM_EP_2 ## 1 5882079 1235621 802389.8 2127015 3010426 ## 2 13136088 0 5888476.7 0 0 ## 3 0 5872301 8928660.8 2478597 6995790 ## 4 2653241 14846810 39848291.1 8631368 6878478 ## 5 11300060 5050705 6733985.2 0 0 ## 6 87393916 65529106 69778380.1 162933067 211765680 Numeric Matrices Most heat map function require that the data be in the form of a numeric matrix, where the rows and columns are genes and samples. Recall: matrices are data tables, where all columns and rows have the same data type. Note: data frames are ok for pheatmap(), as long as all the columns are numeric (right now, our data is not all numeric). # Check if an object is a matrix is.matrix(exp_df) ## [1] FALSE # Rename rows with feature (ie. gene name) and remove the feature column rownames(exp_df) &lt;- exp_df$mGeneSym exp_df$mGeneSym &lt;- NULL # equivalent code: exp_df &lt;- exp_df[,-1] # Convert a data frame to a data matrix exp_mat &lt;- as.matrix(exp_df) head(exp_mat) ## BC_E_1 BC_E_2 BC_EP_1 BC_EP_2 LP_E_1 LP_E_2 LP_EP_1 LP_EP_2 ## Abcb10 0 0 0 0 1557708 1013752 4221663 5882079 ## Abcg2 0 0 2163991 1048502 12987493 7697484 6474732 13136088 ## Abhd4 4956153 5124382 13346955 10634977 0 0 0 0 ## Abhd5 0 0 0 0 1255272 4329562 5741534 2653241 ## Acox1 8926818 9756252 7242814 6847158 4069287 6442152 19309447 11300060 ## Ada 12920739 9339090 3126248 8926815 45120667 77396731 80759779 87393916 ## LM_E_1 LM_E_2 LM_EP_1 LM_EP_2 ## Abcb10 1235621 802389.8 2127015 3010426 ## Abcg2 0 5888476.7 0 0 ## Abhd4 5872301 8928660.8 2478597 6995790 ## Abhd5 14846810 39848291.1 8631368 6878478 ## Acox1 5050705 6733985.2 0 0 ## Ada 65529106 69778380.1 162933067 211765680 Log normalization Usually, expression data has large ranges of values. This will be scaled in the heatmap but we may lose sight of small differences. And so, we log our data. We must deal with the zeros before log(0) is negative infinity (cant plot -Inf). # Check if there are any zeros in the data any(exp_mat == 0) ## [1] TRUE # Impute 0 with 1 exp_mat[exp_mat == 0] &lt;- 1 # Log2-transform data exp_mat &lt;- log2(exp_mat) # Alternatively, log2(exp_mat + 1) adds 1 to all values before log transformation Now lets make our heatmaps.. R base heatmap: heatmap() The built-in R heatmap() function [in stats package] can be used. heatmap(x = exp_mat) # x is a numeric matrix, high values are in red and low values are in yellow 9.2 pheatmap() Use the pheatmap (pretty heat map package) for more customizations. # Install and load package # install.packages(&quot;pheatmap&quot;) library(pheatmap) # Make a simple heatmap using pheatmap() function call pheatmap(exp_mat) # input: numeric matrix 9.2.1 Modify row and column names pheatmap allows you to specify font size, change the row/column names, remove the names, and much more. pheatmap(exp_mat, show_rownames = F, # hide row names fontsize_col = 2, # fontsize of column labels (sample names) cellwidth = 3) # width of columns 9.3 Scaling Usually, we scale by our features (genes) to normalize gene expression across different samples. - argument built in to heatmap function call - a character indicating if the values should be centered and scaled in the row direction, column direction, or none pheatmap(exp_mat, show_rownames = F, scale = &quot;row&quot;) #default scale You can scale the expression matrix before plotting the heatmap as well. compute z-scores - Z-score normalization is a strategy of normalizing data that avoids outlier issue by considering mean and standard deviation Read more: https://www.codecademy.com/articles/normalization # Compute z-scores to plot on heat map # apply() performs a computation/function over rows (1) or columns (2) in a dataframe or matrix z_exp_mat &lt;- apply(exp_mat, 1, function(x) (x - mean(x)) / sd(x)) # Transpose matrix, since apply() rotates data frame z_exp_mat &lt;- t(z_exp_mat) # This is your input data matrix pheatmap(z_exp_mat, show_rownames = F, scale = &quot;row&quot;) rescale to specified min/max using rescale() from the scales package e.g. make range of {-3.2 to 4} to {-2 to 2}) # install.packages(&quot;scales&quot;) library(scales) # Look at range (minimum and maximum) range(exp_mat) ## [1] 0.00000 34.53543 # -- rescale whole matrix # Rescale whole matrix - this just looks like the first heatmap we made exp_mat2 &lt;- rescale(x = exp_mat, # numeric matrix to = c(-2, 2)) # new range # In your heatmap function call, specify the scale = &quot;none&quot; to preserve the range pheatmap(exp_mat2, show_rownames = F, scale = &quot;none&quot;) # -- rescale each row seperately # Rescale each row seperately exp_mat2 &lt;- apply(exp_mat, 1, function(x) rescale(x, c(-2, 2))) # Transpose when using the apply function exp_mat2 &lt;- t(exp_mat2) # Plot heatmap - remember to transpose when pheatmap(exp_mat2, show_rownames = F, scale = &quot;none&quot;) # Look at new range (minimum and maximum) range(exp_mat2) ## [1] -2 2 9.4 Heatmap Colours Its possible to specify a color palette using the argument col, which can be defined as follow: use colorRampPalette() to make a palette and multiply by a number to create a gradient # Using custom colors: col_palette &lt;- colorRampPalette(c(&quot;red&quot;, &quot;white&quot;, &quot;blue&quot;)) (256) # 256 is the number of colours this function will create scales::show_col(col_palette) #show colour palette # Using RColorBrewer color palette: library(&quot;RColorBrewer&quot;) RColorBrewer::display.brewer.all() col_palette &lt;- colorRampPalette(brewer.pal(10, &quot;PuOr&quot;)) (256) #pick a palette and multiply by 256 using () # Show on heatmap pheatmap(exp_mat, show_rownames = F, scale = &quot;row&quot;, col = col_palette) # specify colour palette 9.5 Clustering methods clustering refers to visualizing groups of similar values together via a dendogram (tree-like object) and is always unsupervised in heatmaps rows and columns are clustered independent of one another Set cluster_cols and cluster_rows to FALSE to prevent clustering. Default is TRUE (via euclidean distance and complete linkage). pheatmap(exp_mat, show_rownames = F, scale = &quot;row&quot;, col = col_palette, cluster_cols = F, # specify column clustering cluster_rows = F # specify row clustering ) Most heatmap packages have a clustering method argument in the function call. pheatmap(exp_mat, show_rownames = F, scale = &quot;row&quot;, col = col_palette, clustering_method = &quot;complete&quot;) # specify clustering method - select one of: ward.D&quot;, &quot;ward.D2&quot;, &quot;single&quot;, &quot;complete&quot;, &quot;average&quot; (= UPGMA), &quot;mcquitty&quot; (= WPGMA), &quot;median&quot; (= WPGMC) or &quot;centroid&quot; (= UPGMC) # Note: you can hide dendograms by setting arguments treeheight_row and/or treeheight_col to 0 You can also make hierarchical cluster (hc) objects (i.e dendogram-like structures) 1. First make a distance matrix object using dist() # Make distance matrices for columns (sample) dist_cols &lt;- dist(t(exp_mat), method = &quot;manhattan&quot;) #default - select one of: one of &quot;euclidean&quot;, &quot;maximum&quot;, &quot;manhattan&quot;, &quot;canberra&quot;, &quot;binary&quot; or &quot;minkowski&quot; # Make distance matrices for rows (genes) dist_rows &lt;- dist(exp_mat, method = &quot;euclidean&quot;) # Note: Can also make a correlation matrix into a distance matrix by subtracting values from 1 dist_cols &lt;- as.dist(1 - cor(exp_mat, method = &quot;pearson&quot;)) dist_rows &lt;- as.dist(1 - cor(t(exp_mat), method = &quot;pearson&quot;)) Then build hierachal clustering objects using hclust() # Make hclust object for columns hc_cols &lt;- hclust(dist_cols, method = &quot;complete&quot;) plot(hc_cols) # Repeat for rows hc_rows &lt;- hclust(dist_rows, method = &quot;complete&quot;) Pass these objects into your heatmap function call pheatmap(exp_mat, show_rownames = F, scale = &quot;row&quot;, col = col_palette, cluster_cols = hc_cols, # specify column clustering cluster_rows = hc_rows # specify row clustering ) 9.6 Create annotations Annotations are important components of a heatmap that it shows additional information that associates with rows or columns in the heatmap. Annotations in pheatmap are in the form of data frames. Annotation column (sample information) # Get column names colnames(exp_mat) ## [1] &quot;BC_E_1&quot; &quot;BC_E_2&quot; &quot;BC_EP_1&quot; &quot;BC_EP_2&quot; &quot;LP_E_1&quot; &quot;LP_E_2&quot; &quot;LP_EP_1&quot; ## [8] &quot;LP_EP_2&quot; &quot;LM_E_1&quot; &quot;LM_E_2&quot; &quot;LM_EP_1&quot; &quot;LM_EP_2&quot; # Make annotation column ann_col &lt;- data.frame(CellType = c(&quot;BC&quot;, &quot;BC&quot;, &quot;BC&quot;, &quot;BC&quot;, &quot;LP&quot;, &quot;LP&quot;, &quot;LP&quot;, &quot;LP&quot;, &quot;LM&quot;, &quot;LM&quot;, &quot;LM&quot;, &quot;LM&quot;), Hormone = c(&quot;E&quot;, &quot;E&quot;, &quot;EP&quot;, &quot;EP&quot;, &quot;E&quot;, &quot;E&quot;, &quot;EP&quot;, &quot;EP&quot;, &quot;E&quot;, &quot;E&quot;, &quot;EP&quot;, &quot;EP&quot;)) # Rename row names of annotation column dataframe as the column names of matrix (must match) rownames(ann_col) &lt;- colnames(exp_mat) Note: instead of passing in that huge vector for cell type, these lines of code do exactly the same thing # for cell type rep(c(&quot;BC&quot;, &quot;LP&quot;, &quot;LM&quot;), each = 4) ## [1] &quot;BC&quot; &quot;BC&quot; &quot;BC&quot; &quot;BC&quot; &quot;LP&quot; &quot;LP&quot; &quot;LP&quot; &quot;LP&quot; &quot;LM&quot; &quot;LM&quot; &quot;LM&quot; &quot;LM&quot; gsub(&quot;_.*&quot;, &quot;&quot;, colnames(exp_mat)) ## [1] &quot;BC&quot; &quot;BC&quot; &quot;BC&quot; &quot;BC&quot; &quot;LP&quot; &quot;LP&quot; &quot;LP&quot; &quot;LP&quot; &quot;LM&quot; &quot;LM&quot; &quot;LM&quot; &quot;LM&quot; # for hormone treatement rep(c(&quot;E&quot;, &quot;EP&quot;), each = 2, times = 3) ## [1] &quot;E&quot; &quot;E&quot; &quot;EP&quot; &quot;EP&quot; &quot;E&quot; &quot;E&quot; &quot;EP&quot; &quot;EP&quot; &quot;E&quot; &quot;E&quot; &quot;EP&quot; &quot;EP&quot; Annotation rows (gene information) If you have to provide annotation for features, make a data frame (just like annotation column) and rename rows as genes (same order as your matrix) ann_row &lt;- NA Plot heatmap pheatmap(exp_mat, scale = &quot;row&quot;, show_rownames = F, col = col_palette, annotation_col = ann_col, # annotation column (sample info) annotation_row = ann_row # annotation rows (gene info) ) Make colours for your annotations - Make a list object of the annotation colors - List elements have the same names as the columns of the annotation data frames - Vector elements have same names as values # Make annotation colours list ann_colors &lt;- list( CellType = c(BC=&quot;red&quot;, LP=&quot;blue&quot;, LM=&quot;darkgreen&quot;), Hormone = c(E = &quot;black&quot;, EP = &quot;purple&quot;) ) # Plot heatmap pheatmap(exp_mat, scale = &quot;row&quot;, show_rownames = F, col = col_palette, annotation_col = ann_col, # annotation column (sample info) annotation_row = ann_row, # annotation rows (gene info) annotation_colors = ann_colors # annotation colours ) Save pheatmap to file - Add title using main = - Save to file using filename = (Currently following formats are supported: png, pdf, tiff, bmp, jpeg) # Plot heatmap and save to file pheatmap(exp_mat, scale = &quot;row&quot;, show_rownames = F, col = col_palette, annotation_col = ann_col, annotation_colors = ann_colors, main = &quot;My heatmap&quot;,# add a title filename = &quot;my_heatmap.png&quot;) # save as png to current working directory 9.7 Practice Motor trend car road tests (mtcars) Fuel consumption and 10 additional aspects (variables) of automobile design tested in 1974 are given in an in-built R dataset called mtcars. a) Look at the first rows of the data frame (using head()) b) Look at the structure, are all the data numeric? (use str()) c) Convert the data frame to a data matrix into a new variable. d) Add 1 to all values and apply log2 transformation. e) Make a heatmap (using the pheatmap package). i) Scale by column, ii) use clustering method ward.D, iii) set cell width to 10, iv) pick 9 colours from RColorBrewer color palette RdPu and make a palette with 250 colors for the heatmap, and v) set the title to my heatmap vi) save to a jpeg file called mtcars_heatmap Solution # a) Use head() head(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 # b) Use str() to see the structure str(mtcars) # ANSWER: Yes, all variables are numeric ## &#39;data.frame&#39;: 32 obs. of 11 variables: ## $ mpg : num 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ... ## $ cyl : num 6 6 4 6 8 6 8 4 4 6 ... ## $ disp: num 160 160 108 258 360 ... ## $ hp : num 110 110 93 110 175 105 245 62 95 123 ... ## $ drat: num 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ... ## $ wt : num 2.62 2.88 2.32 3.21 3.44 ... ## $ qsec: num 16.5 17 18.6 19.4 17 ... ## $ vs : num 0 0 1 1 0 1 0 1 1 1 ... ## $ am : num 1 1 1 0 0 0 0 0 0 0 ... ## $ gear: num 4 4 4 3 3 3 3 4 4 4 ... ## $ carb: num 4 4 1 1 2 1 4 2 2 4 ... # c) convert to matrix using as.matrix mtcars_mat &lt;- as.matrix(mtcars) # d) add 1 and log2 mtcars_mat &lt;- mtcars_mat + 1 mtcars_mat &lt;- log2(mtcars_mat) # equivalent: mtcars_mat &lt;- log2(mtcars_mat + 1) # e) plot heatmap library(pheatmap) library(RColorBrewer) pheatmap(mtcars_mat, #e scale = &quot;column&quot;, #i clustering_method = &quot;ward.D&quot;, #ii cellwidth = 10, #iii col = colorRampPalette(brewer.pal(9, &quot;RdPu&quot;)) (256), #iv main = &quot;my_heatmap&quot;, #v filename = &quot;mtcars_heatmap.jpeg&quot; #vi ) "],["dataframe-manipulation.html", "10 Dataframe Manipulation 10.1 Reshape Data 10.2 Pipe operator 10.3 Practice", " 10 Dataframe Manipulation Objective: To reformat data frames using tidyr and learn how to pipe using magrittr Quick Review of vectors and data frames # Store data/parameters in objects in R by assigning it to a variable using: variable_Name &lt;- value # Make a &quot;character&quot; vector called person using function c() people &lt;- c(&quot;Tinky&quot;, &quot;Dipsy&quot;, &quot;Lala&quot;, &quot;Po&quot;) # Assign names to vector using a character vector of same length names(people) &lt;- c(&quot;purple&quot;, &quot;green&quot;, &quot;yellow&quot;, &quot;red&quot;) # Note () brackets reserved for functions # Access data in vectors using [] people[c(1,3)] #use indexing 1st and 3rd elements ## purple yellow ## &quot;Tinky&quot; &quot;Lala&quot; people[1:3] #1st, 2nd and 3rd person ## purple green yellow ## &quot;Tinky&quot; &quot;Dipsy&quot; &quot;Lala&quot; people[-2] #negative indexing to get all values except the 2nd ## purple yellow red ## &quot;Tinky&quot; &quot;Lala&quot; &quot;Po&quot; people[c(T,T,F,F)] #use logical vector to get 1st and 2nd elements ## purple green ## &quot;Tinky&quot; &quot;Dipsy&quot; people[c(&quot;purple&quot;, &quot;yellow&quot;)] #use character vector to get 1st and 3rd elements *for named vectors ## purple yellow ## &quot;Tinky&quot; &quot;Lala&quot; # Make a dataframe or table called &quot;df&quot; to store vectors of different data types # Assign column names for each variable using = df &lt;- data.frame(Person=people, Height=seq(from=180, to=120, length.out = 4)) # Access data in df using [rows_of_interest, cols_of_interest] df[1,] #1st row ## Person Height ## purple Tinky 180 df[,1] #1st column ## [1] &quot;Tinky&quot; &quot;Dipsy&quot; &quot;Lala&quot; &quot;Po&quot; df[,c(T,F)] #1st column ## [1] &quot;Tinky&quot; &quot;Dipsy&quot; &quot;Lala&quot; &quot;Po&quot; df[,&quot;Person&quot;] #1st column ## [1] &quot;Tinky&quot; &quot;Dipsy&quot; &quot;Lala&quot; &quot;Po&quot; df$Person #1st column ## [1] &quot;Tinky&quot; &quot;Dipsy&quot; &quot;Lala&quot; &quot;Po&quot; # Modify variables in dataframe by re-assignment df$Height &lt;- df$Height + 2 #add 2 to all heights Todays tutorial: Original tutorials: - tidyr: http://www.sthda.com/english/wiki/tidyr-crucial-step-reshaping-data-with-r-for-easier-analyses - magrittr pipe: https://www.datacamp.com/community/tutorials/pipe-r-tutorial - dplyr pipe: https://uoftcoders.github.io/studyGroup/lessons/r/intro/lesson/ 10.1 Reshape Data using tidyr package ways to manipulate dataframes to facilitate organization and improve readability of code Useful functions: gather(): gather (collapse) columns into rows spread(): spread rows into columns separate(): separate one column into multiple using delimiter unite(): unite multiple columns into one using delimiter # # Install package # install.packages(&quot;tidyr&quot;) # Load package into environment to use library(&quot;tidyr&quot;) ## Warning: package &#39;tidyr&#39; was built under R version 4.1.3 10.1.1 Data Take a subset of built-in USArrests data sets (state x violent crimes) head(USArrests) ## Murder Assault UrbanPop Rape ## Alabama 13.2 236 58 21.2 ## Alaska 10.0 263 48 44.5 ## Arizona 8.1 294 80 31.0 ## Arkansas 8.8 190 50 19.5 ## California 9.0 276 91 40.6 ## Colorado 7.9 204 78 38.7 # Create a new data frame with just 4 of the observations and remove 4th column df &lt;- USArrests[c(5,12,32,43), -4] # Add a column to beginning of data frame with state names = row names df &lt;- cbind(state = rownames(df), df) # Remove row names rownames(df) &lt;- NULL gather(): collapse columns into rows collapses multiple columns into key-value pairs converts data format wide to long alternative of melt() function [in reshape2 package] useful in ggplot, applying a function (ex. p_adjust() to multiple samples at once) gather(data, key, value, ) Arguments: data = data frame key, value = Names of key and value columns to create in output value = Specification of columns to gather. Allowed values are: variable names if you want to select all variables between a and e, use a:e if you want to exclude a column name y use -y for more options, see: dplyr::select() Examples of usage: Gather all columns except the column state (-) gather(df, key = &quot;arrest_variable&quot;, #this new column will be your column names value = &quot;arrest_rate&quot;, #values -state) ## state arrest_variable arrest_rate ## 1 California Murder 9.0 ## 2 Idaho Murder 2.6 ## 3 New York Murder 11.1 ## 4 Texas Murder 12.7 ## 5 California Assault 276.0 ## 6 Idaho Assault 120.0 ## 7 New York Assault 254.0 ## 8 Texas Assault 201.0 ## 9 California UrbanPop 91.0 ## 10 Idaho UrbanPop 54.0 ## 11 New York UrbanPop 86.0 ## 12 Texas UrbanPop 80.0 Gather only Murder and Assault columns gather(df, key = &quot;arrest_variable&quot;, value = &quot;arrest_rate&quot;, Murder, Assault) ## state UrbanPop arrest_variable arrest_rate ## 1 California 91 Murder 9.0 ## 2 Idaho 54 Murder 2.6 ## 3 New York 86 Murder 11.1 ## 4 Texas 80 Murder 12.7 ## 5 California 91 Assault 276.0 ## 6 Idaho 54 Assault 120.0 ## 7 New York 86 Assault 254.0 ## 8 Texas 80 Assault 201.0 Note that, the two columns Murder and Assault have been collapsed and the remaining columns (state, UrbanPop and Rape) have been duplicated. Gather all variables between Murder and UrbanPop df2 &lt;- gather(df, key = &quot;arrest_variable&quot;, value = &quot;arrest_rate&quot;, Murder:UrbanPop) spread(): spread two columns into multiple columns spread() does the opposite of gather(). It takes two columns (key and value) and spreads into multiple columns produces a wide data format from a long one alternative of the function cast() [in reshape2 package] spread(data, key, value) Arguments: - key = name of the column whose values will be used as column headings. - value = name of the column whose values will populate the cells. # Spread df to turn back to the original data spread(df2, key = &quot;arrest_variable&quot;, value = &quot;arrest_rate&quot;) ## state Assault Murder UrbanPop ## 1 California 276 9.0 91 ## 2 Idaho 120 2.6 54 ## 3 New York 254 11.1 86 ## 4 Texas 201 12.7 80 unite(): Unite multiple columns into one takes multiple columns and paste them together into one. unite(data, col, , sep = _) Arguments: col = The new (unquoted) name of column to add. sep = Separator to use between values # unites the columns Murder and Assault df4 &lt;- unite(df, col = &quot;Murder_Assault&quot;, Murder, Assault, sep = &quot;_&quot;) df4 ## state Murder_Assault UrbanPop ## 1 California 9_276 91 ## 2 Idaho 2.6_120 54 ## 3 New York 11.1_254 86 ## 4 Texas 12.7_201 80 separate(): separate one column into multiple seperate() does the opposite of unite() takes values inside a single character column and separates them into multiple columns separate(data, col, into, sep = [^[:alnum:]]+) Arguments: col = Unquoted column names into = Character vector with names of new columns to be created sep = Separator between columns: If character, is interpreted as a regular expression If numeric, interpreted as positions to split at # Separate the column Murder_Assault [in df4] into two columns Murder and Assault: separate(df4, col = &quot;Murder_Assault&quot;, into = c(&quot;Murder&quot;, &quot;Assault&quot;), sep = &quot;_&quot;) ## state Murder Assault UrbanPop ## 1 California 9 276 91 ## 2 Idaho 2.6 120 54 ## 3 New York 11.1 254 86 ## 4 Texas 12.7 201 80 Alternative forms: gather_(), spread_(), unite_() - useful when making your own functions # Make variable names (ie. would be arguments in your functions) col_names &lt;- c(&quot;Murder&quot;, &quot;Assault&quot;) key_column &lt;- &quot;arrest_variable&quot; value_column &lt;- &quot;arrest_rate&quot; # opposite functions: # alt to gather() - wide to long format df2 &lt;- gather_(df, key_col = key_column, value_col = value_column, gather_cols = col_names) # define columns to gather ## Warning: `gather_()` was deprecated in tidyr 1.2.0. ## i Please use `gather()` instead. # alt to spread() - long to wide format spread_(df2, key = &quot;arrest_variable&quot;, value = &quot;arrest_rate&quot;) ## Warning: `spread_()` was deprecated in tidyr 1.2.0. ## i Please use `spread()` instead. ## state UrbanPop Assault Murder ## 1 California 91 276 9.0 ## 2 Idaho 54 120 2.6 ## 3 New York 86 254 11.1 ## 4 Texas 80 201 12.7 # opposite functions: # alt to unite() - unite many columns into one df4 &lt;- unite_(df, col = &quot;Murder_Assault&quot;, from = c(&quot;Murder&quot;, &quot;Assault&quot;), sep = &quot;_&quot;) ## Warning: `unite_()` was deprecated in tidyr 1.2.0. ## i Please use `unite()` instead. # alt to seperate() - seperate one column into multiple separate_(df4, col = &quot;Murder_Assault&quot;, into = c(&quot;Murder&quot;, &quot;Assault&quot;), sep = &quot;_&quot;) ## Warning: `separate_()` was deprecated in tidyr 1.2.0. ## i Please use `separate()` instead. ## state Murder Assault UrbanPop ## 1 California 9 276 91 ## 2 Idaho 2.6 120 54 ## 3 New York 11.1 254 86 ## 4 Texas 12.7 201 80 10.2 Pipe operator in R it is %&gt;% pipes are used to chain multiple operations similar to how the Bash shell | pipe works forward-pipe operator is %&gt;% (in magrittr and dplyr packages) # install.packages(&quot;magittr&quot;) library(magrittr) ## ## Attaching package: &#39;magrittr&#39; ## The following object is masked from &#39;package:tidyr&#39;: ## ## extract x %&gt;% f is equivalent to f(x). Read more: https://www.datacamp.com/community/tutorials/pipe-r-tutorial advantages: decrease development time and to improve readability and maintainability of code Example 1 # First, df is passed to gather() function # Next, the output of gather() is passed to some functions for transformations.. # Then, we convert to its original data format by unite() function new_df &lt;- df %&gt;% # convert to long format gather(key = &quot;arrest_variable&quot;, value = &quot;arrest_rate&quot;, Murder:UrbanPop) %&gt;% # Apply some transaformations here #.. # return to original wide format unite(col = &quot;attribute_estimate&quot;, &quot;arrest_variable&quot;, &quot;arrest_rate&quot;) # note: we don&#39;t keep mentioning the &quot;df&quot; object because that is the data being passed on Example 2: # Manipulate data, but combine operations using pipe new_df &lt;- df %&gt;% subset(Assault &gt; 200) %&gt;% transform(AttemptedMurder = Murder %&gt;% multiply_by(0.4251)) %&gt;% print %&gt;% plot ## state Murder Assault UrbanPop AttemptedMurder ## 1 California 9.0 276 91 3.82590 ## 3 New York 11.1 254 86 4.71861 ## 4 Texas 12.7 201 80 5.39877 # # Explanation ---- # new_df &lt;- # final output will be assigned to this variable # df %&gt;% # pass in original data frame.. # subset(Assault &gt; 200) %&gt;% # subset so Assault column &gt; 200 # transform(AttemptedMurder = Murder %&gt;% multiply_by(0.4251)) %&gt;% # add a new column # print %&gt;% # print to console # boxplot # visualize and save plot 10.3 Practice The built-in R dataset ChickWeight provides experimental data on the effect of diet on early growth of chicks. Look at the structure of the data (str()). How many rows are there? This data is presented in a long format. Spread the counts data across columns in wide format specified by the key Time and value weight. Save output a variable df. Since the new columns are the timepoints of the experiment (0:21), unite these back into a single column called Timepoint. Save in a variable called df2. Do b) and c) in a single line of code using a pipe operator. That is, make df2 without producing df. Solution # # a) use str() # str(ChickWeight) # # To find number of rows, look at how many observations there are (obs.) # # or use nrow() or dim() # nrow(ChickWeight) # dim(ChickWeight) # # ANSWER: 578 # # # b) use spread() # library(tidyr) # df &lt;- spread(ChickWeight, key = &quot;Time&quot;, value = &quot;weight&quot;) # # # c) unite # # time_cols &lt;- colnames(df)[3:ncol(df)] # df2 &lt;- unite(df, col=&quot;Timepoint&quot;, c(&quot;0&quot;, &quot;2&quot;, &quot;4&quot;, &quot;6&quot;, &quot;8&quot;, &quot;10&quot;, &quot;12&quot;, &quot;14&quot;, &quot;16&quot;, &quot;18&quot;, &quot;20&quot;, &quot;21&quot;), sep = &quot;_&quot;) # # # d) use %&gt;% from dplyr # library(magrittr) # df2 &lt;- ChickWeight %&gt;% # spread(key = &quot;Time&quot;, value = &quot;weight&quot;) %&gt;% # unite(col=&quot;Timepoint&quot;, c(&quot;0&quot;, &quot;2&quot;, &quot;4&quot;, &quot;6&quot;, &quot;8&quot;, &quot;10&quot;, &quot;12&quot;, &quot;14&quot;, &quot;16&quot;, &quot;18&quot;, &quot;20&quot;, &quot;21&quot;), sep = &quot;_&quot;) "],["search-and-conditions.html", "11 Search and Conditions 11.1 General Expressions 11.2 Conditions 11.3 any() and all() 11.4 Operators 11.5 ifelse() 11.6 Practice", " 11 Search and Conditions Objective: To learn about control flow (decision making) structures in R, mainly if/else We will cover: - grep and grepl - conditional operator (review) - if{}else{} - ifelse() Recall: logical is a basic data type in R. The values are either TRUE or FALSE. (short-form T or F) # Examples x &lt;- T# logical value is.logical(x) # returns a logical ## [1] TRUE x &lt;- c(T, F, T) #logical vector 11.1 General Expressions regular expressions can be used to see whether a pattern exists inside a character string or a vector of character strings functions: grepl() = returns a logical vector; TRUE when a pattern is found in the corresponding character string grep() = returns a numeric vector of indices of the character strings that contains the pattern Arguments: - pattern = regular expression you want to match for - x = character vector from which matches should be sought Read more: https://bookdown.org/rdpeng/rprogdatascience/regular-expressions.html # Define a character vector with emails emails &lt;- c(&quot;ka@gmail.com&quot;, &quot;edu@who.int&quot;, &quot;me@gmail.com&quot;, &quot;invalid.edu&quot;, &quot;jane@utoronto.ca&quot;, &quot;jane@gmail.com&quot;) # Search for emails with &quot;gmail.com # use grep grep(pattern = &quot;gmail.com&quot;, x = emails) ## [1] 1 3 6 # use grepl is.gmail &lt;- grepl(pattern = &quot;gmail.com&quot;, x = emails) is.gmail ## [1] TRUE FALSE TRUE FALSE FALSE TRUE # now you can index the emails vector emails[is.gmail] ## [1] &quot;ka@gmail.com&quot; &quot;me@gmail.com&quot; &quot;jane@gmail.com&quot; 11.2 Conditions Decision making is important in programming. Conditions are statements that are created by the programmer which evaluates actions in the code to check if its true or false. if/else statements This is achieved using the conditional if..else statement if (test_expression) { statement } The condition, test_expression must return TRUE or FALSE. If it returns TRUE, the block of code (ie. statement) inside the curly brackets will be run. # Example 1 x &lt;- -3 # Read the following as: if x is less than 0, print &quot;x is a negative number&quot; if(x &lt; 0){ print(&quot;X is a negative number.&quot;) } ## [1] &quot;X is a negative number.&quot; # Example 2 values &lt;- 1:400 do_log &lt;- T # If do_log is TRUE, we log the values in the brackets if(do_log){ print(&quot;do_log is TRUE&quot;) values &lt;- log(values) } ## [1] &quot;do_log is TRUE&quot; You may pair the if{} statement with an else (optional). If the test expression for if is FALSE, the code within else{} will run. if (test_expression) { statement1 } else { statement2 } x &lt;- -3 # Read the following as: if x is less than 0, print &quot;x is a negative number&quot; if(x &lt; 0){ print(&quot;X is a negative number.&quot;) }else{ print(&quot;X is a positive number.&quot;) } ## [1] &quot;X is a negative number.&quot; Note: you can also have an ifelse ladder - It allows you execute a block of code among more than 2 alternatives. if ( test_expression1) { statement1 } else if ( test_expression2) { statement2 } else if ( test_expression3) { statement3 } else { statement4 } x &lt;- 4 # Read the following as: if x is less than 0, print &quot;x is a negative number&quot; if(x &lt; 0){ print(&quot;X is a negative number.&quot;) } else if (x &gt; 0) { print(&quot;X is a positive number.&quot;) } else { print(&quot;X is 0.&quot;) } ## [1] &quot;X is a positive number.&quot; 11.3 any() and all() Check whether any or all of the elements of a vector are TRUE. # continuing emails example... # Check if any emails are gmail if(any(grepl(&quot;gmail.com&quot;, emails))){ print(&quot;There are gmail accounts in the emails vector.&quot;) }else{ print(&quot;There are no gmail accounts.&quot;) } ## [1] &quot;There are gmail accounts in the emails vector.&quot; # check if all of the emails are gmail if(all(grepl(&quot;gmail.com&quot;, emails))){ print(&quot;All emails are gmail accounts.&quot;) }else{ print(&quot;Not all emails are gmail accounts.&quot;) } ## [1] &quot;Not all emails are gmail accounts.&quot; 11.4 Operators Make test expressions using logical and boolean operators Recall from tutorial 1.. Logical operators return TRUE or FALSE, important for later on when we learn about control structures Relational operators used to compare between values &lt; for less than \\&gt; for greater than &lt;= for less than or equal to \\&gt;= for greater than or equal to == for equal to each other != not equal to each other Boolean operators used as conjunctions for logical operations ! Logical NOT # convert &amp; Element-wise logical AND # will be false if at least one element is false Element-wise logical OR # will be true if at least one element is true # Assign logical values to variables im_tall &lt;- TRUE im_short &lt;- FALSE im_nice &lt;- TRUE # NOT !im_tall # I&#39;m NOT tall = FALSE ## [1] FALSE # AND im_nice &amp; im_short ## [1] FALSE im_nice &amp; im_tall ## [1] TRUE # OR im_nice | im_short ## [1] TRUE # combine using parentheses (not square brackets or braces) # like BEDMAS - perform what&#39;s in () brackets first (im_nice | im_short) &amp; im_tall ## [1] TRUE Combine Boolean operators with functions that return logical values. # check if any of the emails are not gmail using NOT ! if(any(! grepl(&quot;gmail.com&quot;, emails))){ print(&quot;Some or all emails are not gmail accounts.&quot;) } ## [1] &quot;Some or all emails are not gmail accounts.&quot; 11.5 ifelse() Say you have an if/else statement where youre assigning a value to a variable based on a condition. Example x &lt;- 20 if(x &lt; 0){ result &lt;- &quot;negative&quot; }else{ result &lt;- &quot;positive&quot; } You can use the ifelse() function in R to shorten this code. ifelse(test_expression, x, y) where if test_expression is T, x is returned if T, else y is returned Read more: https://www.datamentor.io/r-programming/ifelse-function/ result &lt;- ifelse(x &lt; 0, &quot;negative&quot;, &quot;positive&quot;) # If x is between 10 and 30, return x, or else add 30 to x result &lt;- ifelse(x &lt; 30 &amp; x &gt; 10, x, x+30) 11.6 Practice Define a numeric variable, x, that belongs to any number you like. If x is less than 10, print x is less than 10 to the console. Add an else part to your if statement. print x is not less than 10 to the console. Define a vector of 5 numeric values, called v. Print the values in v that are greater than x to console. Solution # a) x &lt;- 5 # b) if(x &lt; 10){ print(&quot;x is less than 10&quot;) } ## [1] &quot;x is less than 10&quot; # c) if(x &lt; 10){ print(&quot;x is less than 10&quot;) }else{ print(&quot;x is not less than 10&quot;) } ## [1] &quot;x is less than 10&quot; # d) v &lt;- 3:7 # or v &lt;- c(3,52,7,2,31) # e) v[v&gt;x] ## [1] 6 7 "],["repetitive-jobs.html", "12 Repetitive Jobs 12.1 Functions 12.2 Loops 12.3 Vectorization 12.4 Intro to apply 12.5 Practice", " 12 Repetitive Jobs Objective: To learn about tools to prevent copying and pasting the same code to replicate instructions We will cover: - how to use functions (review) - make your own function(){} - loops - vectorization - apply family (apply(), lapply()) 12.1 Functions Recall: A quick note on functions Functions are a group of statements that together perform a specific task Functions have a name, e.g. setwd, getwd We can call functions (also called commands in this context) in R for convenience (so we dont have to rewrite the code) Use ? or help() command To find information for a particular function ?print ## starting httpd help server ... done help(print) Functions have the format: function_name( arguments ) Arguments are required or optional parameters used by the function to accomplish the action Functions can return a value (or not) # Type a comma and press tab to see arguments (function parameters) in RStudio print(x = &quot;Hello world&quot;) ## [1] &quot;Hello world&quot; print(x = 33.9431249, digits = 4) ## [1] 33.94 How to define a function: name_of_function &lt;- function(list_of_arguments){ # code to do what function wants } arguments/args: names of variables you will use in your function (seperated by commas, within parantheses) return value: the value that is returned by a function (optional) - use return() Make a function using function() Make a function that adds 2 values, x and y add &lt;- function(x, y) { #arguments within parantheses x.y.sum &lt;- x + y # body of function within {} return(x.y.sum) # return value specified in return() } Call your function the same way you use any other. add(4,5) #returns 9; if not saved to a variable, it will print ## [1] 9 # add(4) # Error in add(4) : argument &quot;y&quot; is missing, with no default Automatic Returns - In R, it is not necessary to include the return statement. R automatically returns whichever variable is on the last line of the body of the function. Default arguments Set defaults if not specified by user. # Define a function add &lt;- function(x, y=0) { # x is required argument, but if y is not specified, it is 0 x.y.sum &lt;- x + y return(x.y.sum) } # Use function add(4,5) ## [1] 9 add(4) ## [1] 4 Define a function lb.to.kg that converts weights from pounds (lb) to kilogram (kg): # for an approximate result, divide the mass value by 2.205 lb.to.kg &lt;- function(wt_lb) { #argument within parantheses wt_kg &lt;- wt_lb/2.205 # body of function within {} wt_kg &lt;- round(wt_kg, digits = 3) return(wt_kg) # return value specified in return() } # Let&#39;s try running our function. Calling our own function is no different from calling any other function: lb.to.kg(32) ## [1] 14.512 lb.to.kg(212) ## [1] 96.145 Summary: - Define a function using name &lt;- function(args) { body } - Call a function using name(values.. ) taste of how larger programs are built: we define basic operations, then combine them in ever-larger chunks to get the effect we want. 12.2 Loops Based on following tutorial: https://swcarpentry.github.io/r-novice-inflammation/03-loops-R/index.html Suppose we want to print each word in a sentence. One way is to use six print statements: # Make a character vector sentence1 &lt;- c(&quot;Try&quot;, &quot;printing&quot;, &quot;this&quot;) # Make a function to print each value in sentence vector print_sentence &lt;- function(sentence) { print(sentence[1]) print(sentence[2]) print(sentence[3]) } # Call function print_sentence(sentence1) ## [1] &quot;Try&quot; ## [1] &quot;printing&quot; ## [1] &quot;this&quot; However this function wont work as intended (doesnt scale and fragile) if there are more than 3 values in sentence argument. # Make another sentence vector sentence2 &lt;- c(&quot;Let&quot;, &quot;the&quot;, &quot;computer&quot;, &quot;do&quot;, &quot;the&quot;, &quot;work&quot;) # Call function print_sentence(sentence2) ## [1] &quot;Let&quot; ## [1] &quot;the&quot; ## [1] &quot;computer&quot; Or if the sentence is shorter, NAs (missing values) are introduced. # Make another sentence vector sentence3 &lt;- c(&quot;Try&quot;, &quot;this&quot;) # Call function print_sentence(sentence3) ## [1] &quot;Try&quot; ## [1] &quot;this&quot; ## [1] NA Loop - All modern programming languages provide special constructs that allow for the repetition of instructions or blocks of instructions. There are 3 main types of loops in R: for, while, repeat You can add break; and next; to skip a iteration if it does not passed a test (ie. condition) Read more: https://www.datacamp.com/community/tutorials/tutorial-on-loops-in-r The for loop construct for (variable in collection) { # do things with variable } Eg. make a for loop # Make a for loop to print out each element in sentence1 for (word in sentence1){ # word will take on the value of &quot;sentence1&quot; element by element until there are no elements left # print the current word print(word) } ## [1] &quot;Try&quot; ## [1] &quot;printing&quot; ## [1] &quot;this&quot; Add a condition # Make a for loop to print out each element in sentence1 for (word in sentence1){ # word will take on the value of &quot;sentence1&quot; element by element until there are no elements left # Skip current iteration if the current word is equal to &quot;printing&quot; if(word == &quot;printing&quot;){ next; } # print the current word print(word) } ## [1] &quot;Try&quot; ## [1] &quot;this&quot; Eg. make a while loop # Intialize an index counter i &lt;- 1 # Make a while loop to print out each element in sentence1 # Note: length() is the number of elements in a vector or list while (i &lt;= length(sentence1)){ # i will test this condition and run the code within {} until it is FALSE # Define word variable by indexing sentence1 word &lt;- sentence1[i] # print the current word print(word) # Update counter by 1 - i.e. move to the next index - must do this or you&#39;ll end up with an infinite loop! i &lt;- i+1 } ## [1] &quot;Try&quot; ## [1] &quot;printing&quot; ## [1] &quot;this&quot; Applications: - processing/analyzing multiple files (look at linked tutorial) - plotting graphs from columns in same dataframe # eg. Use a for loop to apply same preprocessing steps to multiple csv files for (filename in list.files(pattern=&quot;csv&quot;)){ # Read csv file into a variable called df df &lt;- read.csv(filename) if(is.null(df)){ next; } # downstream processing df } 12.3 Vectorization Alternative to looping Vectorization is a feature of R that allows you to apply an operation to data/vectors at the same time This makes code more readable most functions in R perform vectorization intrinsically, such as colSums(), rowMeans(), and even basic arithmetic operations (e.g +, -, *) e.g. Power of vectorization: Add 2 to all values # Define a numeric vector called values values &lt;- c(3,5,6,10) # In many programming languages you may have to run a loop to do this for(value in values){ new_value &lt;- value + 2 print(new_value) } ## [1] 5 ## [1] 7 ## [1] 8 ## [1] 12 # But R lets you add 2 to all values at once - this is called vectorization values + 2 ## [1] 5 7 8 12 12.4 Intro to apply apply family functions utilize the concept of vectorization functions: apply(), sapply(), lapply(), mapply(), rapply(), tapply(), vapply() within these commands, you may apply a function or operation to the values put name of function into FUN (no parantheses) or make your own most frequently used are: lapply (list apply) applies a function on 1D data - list or vector returns a list note: use unlist() to convert the resulting list to vector # e.g. print vector elements lapply(sentence1, FUN = print) ## [1] &quot;Try&quot; ## [1] &quot;printing&quot; ## [1] &quot;this&quot; ## [[1]] ## [1] &quot;Try&quot; ## ## [[2]] ## [1] &quot;printing&quot; ## ## [[3]] ## [1] &quot;this&quot; # e.g. add 2 to each element by making your own function lapply(values, FUN = function(value){ value + 2 }) ## [[1]] ## [1] 5 ## ## [[2]] ## [1] 7 ## ## [[3]] ## [1] 8 ## ## [[4]] ## [1] 12 apply apply a function to 2D data - matrix or data frame specify if function should be apply on rows or columns (using MARGIN argument: 1 = row, 2 = column) # Read input table df &lt;- read.delim(file = &quot;07-Casey-mamm-mouse-proteome-sample.txt&quot;, row.names = 1) # Get standard deviation of columns apply(df, MARGIN = 2, FUN = sd) ## BC_E_1 BC_E_2 BC_EP_1 BC_EP_2 LP_E_1 LP_E_2 LP_EP_1 ## 216497329 250258435 175483149 189537235 359922127 271978322 212250113 ## LP_EP_2 LM_E_1 LM_E_2 LM_EP_1 LM_EP_2 ## 238676624 1550773037 1494197893 687720907 625922913 # Transform data to z-scores (which account for sd of each row) z_scores &lt;- apply(df, MARGIN = 1, FUN = function(x){ # in this function, x is a numeric vector of each row (x-mean(x))/sd(x) }) # Look at first 6 rows and 6 columns z_scores[1:6, 1:6] ## Abcb10 Abcg2 Abhd4 Abhd5 Acox1 Ada ## BC_E_1 -0.88084429 -0.8165888 0.02080524 -0.6218765 0.34686146 -0.8860501 ## BC_E_2 -0.88084429 -0.8165888 0.05777697 -0.6218765 0.50786325 -0.9420582 ## BC_EP_1 -0.88084429 -0.3873079 1.86485582 -0.6218765 0.01997860 -1.0392117 ## BC_EP_2 -0.88084429 -0.6085926 1.26884306 -0.6218765 -0.05682232 -0.9485052 ## LP_E_1 -0.05139152 1.7598003 -1.06841075 -0.5106032 -0.59603606 -0.3825228 ## LP_E_2 -0.34103905 0.7103968 -1.06841075 -0.2380836 -0.13543827 0.1221950 # Note apply() has transposed our original matrix; re-transpose using t() z_scores &lt;- t(z_scores) 12.5 Practice Converting cm to in a) Define a function called cm_to_in. This function takes in a numeric variable and converts it from centimeters to inches by dividing the length value by 2.54. Round to 2 significant digits using round(). Return the result. b) Test your function on any number. c) Make a numeric vector of 5 different values called cm_measurements. d) In a loop, - convert the cm vector to inches using your function in a) and save to variable called in_inches - print in_inches to console using print() e) Use the lapply() function to apply your function to each element. f) Pass your vector into your function. Whats the result? This is called vectorization. Solution # a) make a function cm_to_in &lt;- function(value){ # Divide value by 2.54 result &lt;- value/2.54 # Round to 2 digits result &lt;- round(result, digits = 2) return(result) } # b) pass in single numeric value to function cm_to_in(45) ## [1] 17.72 # c) make a numeric vector cm_measurements &lt;- c(35,63,53,67,32) # d) make for loop for(in_cm in cm_measurements){ # Save output of function to variable in_inches &lt;- cm_to_in(in_cm) # Print print(in_inches) } ## [1] 13.78 ## [1] 24.8 ## [1] 20.87 ## [1] 26.38 ## [1] 12.6 # e) use lapply() on vector lapply(cm_measurements, FUN = cm_to_in) ## [[1]] ## [1] 13.78 ## ## [[2]] ## [1] 24.8 ## ## [[3]] ## [1] 20.87 ## ## [[4]] ## [1] 26.38 ## ## [[5]] ## [1] 12.6 # f) pass in whole vector to function cm_to_in(cm_measurements) ## [1] 13.78 24.80 20.87 26.38 12.60 "]]
